{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdb86eec"
      },
      "source": [
        "# Assignment 4: Multilingual BERT and Zero-Shot Transfer (10 Marks)\n",
        "\n",
        "## Due: 31 March 2022\n",
        "\n",
        "Welcome to the 4th and last assignment of the course. In this assignment we will learn how to fine-tune a multilingual BERT or mBERT model on a Natural Language Inference task [XNLI](https://arxiv.org/abs/1809.05053). We will fine-tune the model on English Training data and then evaluate the performance of the fine-tuned models on different languages demonstrating the zero-shot capabilities of mBERT. "
      ],
      "id": "fdb86eec"
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFbonKDMpGiD",
        "outputId": "b298c02a-c1d3-4687-9925-e5100ed94316"
      },
      "id": "QFbonKDMpGiD",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 24 06:38:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb7d9310",
        "outputId": "64e7c9e0-d306-4a9e-da1a-7776b8ca802e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    data_dir = \"gdrive/MyDrive/PlakshaNLP/Assignment4/data/xnli\"\n",
        "except:\n",
        "    data_dir = \"/datadrive/t-kabir/work/repos/PlakshaNLP/source/Assignment4/data/xnli\""
      ],
      "id": "cb7d9310"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f1c0d05",
        "outputId": "cee5d260-ea0f-4b0c-cf16-2c884203f5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 80.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 68.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install matplotlib\n",
        "!pip install transformers\n",
        "!pip install tqdm"
      ],
      "id": "8f1c0d05"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "382573bd"
      },
      "outputs": [],
      "source": [
        "# We start by importing libraries that we will be making use of in the assignment.\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "import tqdm"
      ],
      "id": "382573bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "222e4a45"
      },
      "source": [
        "## XNLI: Task Description\n",
        "\n",
        "XNLI is a multilingual benchmark for Natural Language Inference, that contains training data available in English which was obtained from the popular [MNLI](https://cims.nyu.edu/~sbowman/multinli/), and test and dev sets available for 15 different languages. In NLI, we are given two sentences, one is a premise and other an hypothesis, and the task is to predict whether the hypothesis is i) entialed in the premise, or ii) contradicts the premise, or iii) neutral to the premise. \n",
        "\n",
        "<img src=\"https://i.ibb.co/bd4P20K/nli-examples.jpg\" alt=\"nli-examples\" border=\"0\">\n",
        "\n",
        "This makes NLI a multi-class classification task where we want to predict the correct label out of the three possible classes. We start by loading the dataset into memory. The training set in XNLI is comparitively huge with around 400k examples, which can lead to higher training times. Hence for the purpose of this assignment we will work with a fraction of the full data i.e. ~40k examples"
      ],
      "id": "222e4a45"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "40cf1fe5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_xnli_dataset(lang, split = \"train\"):\n",
        "    filename = os.path.join(data_dir, f\"{split}-{lang}.tsv\")\n",
        "    sentence1s = []\n",
        "    sentence2s = []\n",
        "    labels = []\n",
        "    with open(filename) as f:\n",
        "        for i,line in enumerate(f):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            row = line.split(\"\\t\")\n",
        "            sentence1 = row[0]\n",
        "            sentence2 = row[1]\n",
        "            label = row[2].split(\"\\n\")[0]\n",
        "            sentence1s.append(sentence1)\n",
        "            sentence2s.append(sentence2)\n",
        "            labels.append((label))\n",
        "    \n",
        "    return pd.DataFrame({\n",
        "        \"premise\": sentence1s,\n",
        "        \"hypothesis\" : sentence2s,\n",
        "        \"label\" : labels\n",
        "    })"
      ],
      "id": "40cf1fe5"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "1d0b9f05",
        "outputId": "f6b9e028-65d5-431f-be88-e1f0828e1bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples in training data: 38000\n",
            "Number of examples in validation data: 2000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 premise  \\\n",
              "28951  But the criticism of Java on performance groun...   \n",
              "33322  In 1985 , for example , RCED was asked how the...   \n",
              "24194  During the millennium before the Christian era...   \n",
              "712    I 've always heard you Revolutionists held lif...   \n",
              "28791  If audacity had successfully carried him so fa...   \n",
              "\n",
              "                                              hypothesis          label  \n",
              "28951  It is not fair to criticize Java on performanc...     entailment  \n",
              "33322  RCED was not asked about the Department of Int...  contradiction  \n",
              "24194  Their civilization thrived before the Christia...     entailment  \n",
              "712    I 've constantly heard that you Revolutionists...  contradiction  \n",
              "28791  He had been courageous all the way , and he wa...        neutral  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6a350e8-7645-4632-8e87-ce6577110d94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28951</th>\n",
              "      <td>But the criticism of Java on performance groun...</td>\n",
              "      <td>It is not fair to criticize Java on performanc...</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33322</th>\n",
              "      <td>In 1985 , for example , RCED was asked how the...</td>\n",
              "      <td>RCED was not asked about the Department of Int...</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24194</th>\n",
              "      <td>During the millennium before the Christian era...</td>\n",
              "      <td>Their civilization thrived before the Christia...</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>I 've always heard you Revolutionists held lif...</td>\n",
              "      <td>I 've constantly heard that you Revolutionists...</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28791</th>\n",
              "      <td>If audacity had successfully carried him so fa...</td>\n",
              "      <td>He had been courageous all the way , and he wa...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6a350e8-7645-4632-8e87-ce6577110d94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6a350e8-7645-4632-8e87-ce6577110d94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6a350e8-7645-4632-8e87-ce6577110d94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Load Training data in english\n",
        "train_en_data = load_xnli_dataset(\"en\", \"train\")[:40000]\n",
        "\n",
        "#Like last assignment we will use split the training data to get some validation examples as well\n",
        "train_en_data, val_en_data = train_test_split(train_en_data, test_size=0.05)\n",
        "\n",
        "print(f\"Number of examples in training data: {len(train_en_data)}\")\n",
        "print(f\"Number of examples in validation data: {len(val_en_data)}\")\n",
        "\n",
        "train_en_data.head()"
      ],
      "id": "1d0b9f05"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "96957733"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load Test data in other languages\n",
        "test_langs = [\"ar\", \"bg\", \"de\", \"el\", \"en\", \"es\", \"fr\", \"hi\", \"ru\", \"sw\", \"th\", \"tr\", \"ur\", \"vi\", \"zh\"]\n",
        "\n",
        "lang2test_df = {lang : load_xnli_dataset(lang, \"dev\") for lang in test_langs}"
      ],
      "id": "96957733"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d8bc71b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "2e7a6c0c-386a-4b3f-98f1-2abb5c74de5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Test examples: 2489\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             premise  \\\n",
              "0                       And he said, Mama, I'm home.   \n",
              "1                       And he said, Mama, I'm home.   \n",
              "2  I didn't know what I was going for or anything...   \n",
              "3  I didn't know what I was going for or anything...   \n",
              "4  I didn't know what I was going for or anything...   \n",
              "\n",
              "                                          hypothesis          label  \n",
              "0                              He didn't say a word.  contradiction  \n",
              "1                He told his mom he had gotten home.     entailment  \n",
              "2  I have never been to Washington so when I was ...        neutral  \n",
              "3  I knew exactly what I needed to do as I marche...  contradiction  \n",
              "4  I was not quite certain what I was going to do...     entailment  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddddf38d-29a0-4c8a-8e4b-b210b6e2a36b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>And he said, Mama, I'm home.</td>\n",
              "      <td>He didn't say a word.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>And he said, Mama, I'm home.</td>\n",
              "      <td>He told his mom he had gotten home.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I didn't know what I was going for or anything...</td>\n",
              "      <td>I have never been to Washington so when I was ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I didn't know what I was going for or anything...</td>\n",
              "      <td>I knew exactly what I needed to do as I marche...</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I didn't know what I was going for or anything...</td>\n",
              "      <td>I was not quite certain what I was going to do...</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddddf38d-29a0-4c8a-8e4b-b210b6e2a36b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddddf38d-29a0-4c8a-8e4b-b210b6e2a36b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddddf38d-29a0-4c8a-8e4b-b210b6e2a36b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "print(f\"Number of Test examples: {len(lang2test_df['en'])}\")\n",
        "lang2test_df[\"en\"].head()"
      ],
      "id": "d8bc71b7"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "362ebef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e46498e-d35a-4fa9-f485-f47761aced24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ar test set:\n",
            "                                             premise  \\\n",
            "0                        وقال، ماما، لقد عدت للمنزل.   \n",
            "1                        وقال، ماما، لقد عدت للمنزل.   \n",
            "2  لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...   \n",
            "3  لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...   \n",
            "4  لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                                  لم ينطق ببنت شفة.  contradiction  \n",
            "1                        أخبر أمه أنه قد عاد للمنزل.     entailment  \n",
            "2  لم أذهب إلى واشنطن من قبل، لذا عندما تم تكليفي...        neutral  \n",
            "3  لقد عرفت بالضبط ما الذي احتجت أن أفعله عندما م...  contradiction  \n",
            "4  لم أكن متأكدًا مما سأفعله لذلك ذهبت إلى واشنطن...     entailment  \n",
            "***************************\n",
            "\n",
            "bg test set:\n",
            "                                             premise  \\\n",
            "0                      И той каза: Мамо, у дома съм.   \n",
            "1                      И той каза: Мамо, у дома съм.   \n",
            "2  Не знаех за какво отивам и въобще нищо, но тря...   \n",
            "3  Не знаех за какво отивам и въобще нищо, но тря...   \n",
            "4  Не знаех за какво отивам и въобще нищо, но тря...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                             Той не каза нито дума.  contradiction  \n",
            "1       Той каза на майка си, че се е прибрал вкъщи.     entailment  \n",
            "2  Никога не съм бил във Вашингтон и когато ме на...        neutral  \n",
            "3  Знаех точно какво да направя когато отивах към...  contradiction  \n",
            "4  Не бях съвсем сигурен какво ще направя, така ч...     entailment  \n",
            "***************************\n",
            "\n",
            "de test set:\n",
            "                                             premise  \\\n",
            "0            und er hat gesagt, Mama ich bin daheim.   \n",
            "1            und er hat gesagt, Mama ich bin daheim.   \n",
            "2  Ich wusste nicht was ich vorhatte oder so, ich...   \n",
            "3  Ich wusste nicht was ich vorhatte oder so, ich...   \n",
            "4  Ich wusste nicht was ich vorhatte oder so, ich...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                                Er sagte kein Wort.  contradiction  \n",
            "1  Er sagte seiner Mutter, er sei nach Hause geko...     entailment  \n",
            "2  Ich war noch nie in Washington, deshalb habe i...        neutral  \n",
            "3  Ich wusste genau, was ich tun musste, als ich ...  contradiction  \n",
            "4  Ich war mir nicht ganz sicher was ich tun soll...     entailment  \n",
            "***************************\n",
            "\n",
            "el test set:\n",
            "                                             premise  \\\n",
            "0                  Και είπε, Μαμά, έφτασα στο σπίτι.   \n",
            "1                  Και είπε, Μαμά, έφτασα στο σπίτι.   \n",
            "2  Δεν ήξερα που πήγαινα ή κάτι τέτοιο, έτσι έπρε...   \n",
            "3  Δεν ήξερα που πήγαινα ή κάτι τέτοιο, έτσι έπρε...   \n",
            "4  Δεν ήξερα που πήγαινα ή κάτι τέτοιο, έτσι έπρε...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                                Δεν είπε ούτε λέξη.  contradiction  \n",
            "1            Είπε στην μαμά του ότι είχε πάει σπίτι.     entailment  \n",
            "2  Ποτέ δεν πήγα στην Ουάσινγκτον, οπότε όταν με ...        neutral  \n",
            "3  Ήξερα ακριβώς τι χρειαζόμουν καθώς όδευα προς ...  contradiction  \n",
            "4  Δεν ήμουν αρκετά σίγουρος για το τι θα κάνω, έ...     entailment  \n",
            "***************************\n",
            "\n",
            "en test set:\n",
            "                                             premise  \\\n",
            "0                       And he said, Mama, I'm home.   \n",
            "1                       And he said, Mama, I'm home.   \n",
            "2  I didn't know what I was going for or anything...   \n",
            "3  I didn't know what I was going for or anything...   \n",
            "4  I didn't know what I was going for or anything...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                              He didn't say a word.  contradiction  \n",
            "1                He told his mom he had gotten home.     entailment  \n",
            "2  I have never been to Washington so when I was ...        neutral  \n",
            "3  I knew exactly what I needed to do as I marche...  contradiction  \n",
            "4  I was not quite certain what I was going to do...     entailment  \n",
            "***************************\n",
            "\n",
            "es test set:\n",
            "                                             premise  \\\n",
            "0                    Y él dijo: Mamá, estoy en casa.   \n",
            "1                    Y él dijo: Mamá, estoy en casa.   \n",
            "2  No sabía para qué iba ni nada, así que iba a i...   \n",
            "3  No sabía para qué iba ni nada, así que iba a i...   \n",
            "4  No sabía para qué iba ni nada, así que iba a i...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                            Él no dijo una palabra.  contradiction  \n",
            "1       Le dijo a su madre que había llegado a casa.     entailment  \n",
            "2  Nunca he estado en Washington, así que cuando ...        neutral  \n",
            "3  Sabía exactamente lo que tenía que hacer mient...  contradiction  \n",
            "4  No estaba muy seguro de lo que iba a hacer, as...     entailment  \n",
            "***************************\n",
            "\n",
            "fr test set:\n",
            "                                             premise  \\\n",
            "0           Et il a dit, maman, je suis à la maison.   \n",
            "1           Et il a dit, maman, je suis à la maison.   \n",
            "2  Je ne savais pas dans quoi je me lançais, donc...   \n",
            "3  Je ne savais pas dans quoi je me lançais, donc...   \n",
            "4  Je ne savais pas dans quoi je me lançais, donc...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                             Il n'a pas dit un mot.  contradiction  \n",
            "1             Il a dit à sa mère qu'il était rentré.     entailment  \n",
            "2  Je ne suis jamais allé à Washington et donc qu...        neutral  \n",
            "3  Je savais exactement ce que j'avais à faire qu...  contradiction  \n",
            "4  Je n'étais pas tout à fait certain de ce que j...     entailment  \n",
            "***************************\n",
            "\n",
            "hi test set:\n",
            "                                             premise  \\\n",
            "0                  और उसने कहा, माँ, मैं घर आया हूं।   \n",
            "1                  और उसने कहा, माँ, मैं घर आया हूं।   \n",
            "2  मुझे नहीं पता था कि मैं क्या कर रहा था या कुछ ...   \n",
            "3  मुझे नहीं पता था कि मैं क्या कर रहा था या कुछ ...   \n",
            "4  मुझे नहीं पता था कि मैं क्या कर रहा था या कुछ ...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                             उसने एक शब्द नहीं कहा।  contradiction  \n",
            "1          Uski maa ne bataya ki wo ghar pahuch gaya     entailment  \n",
            "2  मैं कभी वाशिंगटन नहीं गया, इसलिए जब मुझे काम स...        neutral  \n",
            "3  मैं बिल्कुल जानता था कि मुझे वाशिंगटन जाने के ...  contradiction  \n",
            "4  Mujhe kuch nahi pata tha kya karna hai, to mai...     entailment  \n",
            "***************************\n",
            "\n",
            "ru test set:\n",
            "                                             premise  \\\n",
            "0                         И он сказал: Мама, я дома.   \n",
            "1                         И он сказал: Мама, я дома.   \n",
            "2  Я не знал, что мне предстояло сделать и все та...   \n",
            "3  Я не знал, что мне предстояло сделать и все та...   \n",
            "4  Я не знал, что мне предстояло сделать и все та...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                           Он не произнес ни слова.  contradiction  \n",
            "1          Он сказал матери, что уже добрался домой.     entailment  \n",
            "2  Я раньше не был в Вашингтоне, поэтому, получив...        neutral  \n",
            "3  Я точно знал, что мне нужно сделать, когда вхо...  contradiction  \n",
            "4  Я не знал, что мне делать, поэтому я отправилс...     entailment  \n",
            "***************************\n",
            "\n",
            "sw test set:\n",
            "                                             premise  \\\n",
            "0                 Naye akasema, Mama, niko nyumbani.   \n",
            "1                 Naye akasema, Mama, niko nyumbani.   \n",
            "2  Sikujua nini nilichoendea au kitu chochote, hi...   \n",
            "3  Sikujua nini nilichoendea au kitu chochote, hi...   \n",
            "4  Sikujua nini nilichoendea au kitu chochote, hi...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                                 Hakusema chochote.  contradiction  \n",
            "1     Alimwambia mama yake alikuwa amefika nyumbani.     entailment  \n",
            "2  Sijawahi kwenda Washington hivyo wakati nilipo...        neutral  \n",
            "3  Nilijua hasa kile nilichohitaji kufanya  nilip...  contradiction  \n",
            "4  Sikuwa na hakika kabisa nilichokuwa nikienda k...     entailment  \n",
            "***************************\n",
            "\n",
            "th test set:\n",
            "                                             premise  \\\n",
            "0                    และเขาพูดว่า, ม่าม๊า ผมอยู่บ้าน   \n",
            "1                    และเขาพูดว่า, ม่าม๊า ผมอยู่บ้าน   \n",
            "2  ฉันไม่รู้ว่าฉันไปเพื่ออะไรหรือเพื่อสิ่งใด ดังน...   \n",
            "3  ฉันไม่รู้ว่าฉันไปเพื่ออะไรหรือเพื่อสิ่งใด ดังน...   \n",
            "4  ฉันไม่รู้ว่าฉันไปเพื่ออะไรหรือเพื่อสิ่งใด ดังน...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                                  เขาไม่ได้พูดสักคำ  contradiction  \n",
            "1                    เขาบอกเเม่เขาว่าเขาถึงบ้านเเล้ว     entailment  \n",
            "2  ฉันไม่เคยไป กรุงวอชิงตันมาก่อนเลย เพราะเช่นนั้...        neutral  \n",
            "3  ฉันรู้อยู่เเล้วว่าฉันจะต้องทำยังไงจะปรับตัวกับ...  contradiction  \n",
            "4  ฉันไม่ค่อยมั่นใจว่าฉันจะทำอะไร ดังนั้นฉันจึงไป...     entailment  \n",
            "***************************\n",
            "\n",
            "tr test set:\n",
            "                                             premise  \\\n",
            "0                             Ve Anne, evdeyim dedi.   \n",
            "1                             Ve Anne, evdeyim dedi.   \n",
            "2  Ne için gittiğimi falan bilmiyordum, Washingto...   \n",
            "3  Ne için gittiğimi falan bilmiyordum, Washingto...   \n",
            "4  Ne için gittiğimi falan bilmiyordum, Washingto...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                              Bir kelime söylemedi.  contradiction  \n",
            "1                    Annesine eve gittiğini söyledi.     entailment  \n",
            "2  Washington'a hiç gitmedim, bu yüzden oraya ata...        neutral  \n",
            "3  Washington'a yürürken ne yapmam gerektiğini ta...  contradiction  \n",
            "4  Ne yapacağımdan çok emin değildim, o yüzden ra...     entailment  \n",
            "***************************\n",
            "\n",
            "ur test set:\n",
            "                                             premise  \\\n",
            "0              اور اس نے کہا امّی، میں گھر آگیا ہوں۔   \n",
            "1              اور اس نے کہا امّی، میں گھر آگیا ہوں۔   \n",
            "2  مجھے نہیں معلوم تھا کہ میں کیا کرنے جا رہا تھا...   \n",
            "3  مجھے نہیں معلوم تھا کہ میں کیا کرنے جا رہا تھا...   \n",
            "4  مجھے نہیں معلوم تھا کہ میں کیا کرنے جا رہا تھا...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                               وں ا یک لفز نھی بولا  contradiction  \n",
            "1               اسنی اپنی امی کو بتایا کے وں گھر ھیں     entailment  \n",
            "2  میں کبھی واشنگٹن نہیں گیا/گئی چناں چہ جب میرا ...        neutral  \n",
            "3  میں جانتا تھا کہ واشنگٹن کی طرف روانہ ہونے کے ...  contradiction  \n",
            "4  میں بالکل اس بات کا پتا نہی تھا کہ میں کیا کرن...     entailment  \n",
            "***************************\n",
            "\n",
            "vi test set:\n",
            "                                             premise  \\\n",
            "0                  Và anh ấy nói, Mẹ, con đã về nhà.   \n",
            "1                  Và anh ấy nói, Mẹ, con đã về nhà.   \n",
            "2  Tôi đã không biết mình đang hướng tới mục đích...   \n",
            "3  Tôi đã không biết mình đang hướng tới mục đích...   \n",
            "4  Tôi đã không biết mình đang hướng tới mục đích...   \n",
            "\n",
            "                                          hypothesis          label  \n",
            "0                         Anh không nói một lời nào.  contradiction  \n",
            "1                 Anh nói với mẹ rằng anh đã về nhà.     entailment  \n",
            "2  Tôi chưa bao giờ đến Washington nên khi tôi đư...        neutral  \n",
            "3  Tôi biết chính xác những gì tôi cần làm khi tô...  contradiction  \n",
            "4  Tôi đã không hoàn toàn chắc chắn những gì tôi ...     entailment  \n",
            "***************************\n",
            "\n",
            "zh test set:\n",
            "                           premise                          hypothesis  \\\n",
            "0                      他说，妈妈，我回来了。                             他没说一句话。   \n",
            "1                      他说，妈妈，我回来了。                     他告诉他的妈妈他已经回到家了。   \n",
            "2  我不知道我要去干什么还是什么的，所以就去华盛顿指定的地方报到。  我从来没有去过华盛顿，所以当我被派到那里时，为了找地方我都找迷路了。   \n",
            "3  我不知道我要去干什么还是什么的，所以就去华盛顿指定的地方报到。                  在我游行到华盛顿的时候我知道我要什么   \n",
            "4  我不知道我要去干什么还是什么的，所以就去华盛顿指定的地方报到。          我不确定我要做什么，所以我去了华盛顿。我被派去述职。   \n",
            "\n",
            "           label  \n",
            "0  contradiction  \n",
            "1     entailment  \n",
            "2        neutral  \n",
            "3  contradiction  \n",
            "4     entailment  \n",
            "***************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for lang, test_df in lang2test_df.items():\n",
        "    print(f\"{lang} test set:\")\n",
        "    print(test_df.head())\n",
        "    print(\"***************************\\n\")"
      ],
      "id": "362ebef0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bc90924"
      },
      "source": [
        "## mBERT using HuggingFace's transformers library\n",
        "\n",
        "mBERT is a multilingual variant of BERT, which is trained on wikipedia articles in around [100 languages](BertTokenizer). Like monolingual BERT the transformers library also provides pre-trained models and tokenizers for multilingual BERT. To create an instance of one, we only need to specify `\"bert-base-multilingual-cased\"` or `\"bert-base-multilingual-uncased\"` in `BertTokenizer.from_pretrained` and `BertModel.from_pretrained` methods and that's it! See examples below for a demonstration:"
      ],
      "id": "4bc90924"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "821b8b04"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel"
      ],
      "id": "821b8b04"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bfddbd7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2bd17df20df94f8691739e32587bfcd9",
            "8872d2e18ab94ab89198f7a5c7953c28",
            "b3aabdbfbe54402d82db10e4b429eed4",
            "c88e106beec443f48f96679a7ec0e4a6",
            "5d302af0d9cb41529723fa49a980ce88",
            "5119e0d9fa39447bbd6272612f609681",
            "cd7a6c769fb445bf9f66e565782c6fca",
            "56ca8910cd3e4248b2d40fcac7244b8d",
            "25e53c69f9c44607b365a3846121b52b",
            "c5b31063f15247da84e697a8b6e4ad71",
            "c9b5633961ee41528896178aade62344",
            "5c77122f70b94237b64c1e3b37b25eb0",
            "1dd7aef0706545cf9889bf27147decc5",
            "d5c36871914b4e6590d5d26164e34157",
            "95ea78b56cb64e9bae4a92b009fdf9cd",
            "6af601c49b9c4678a488c58cd3e9e2b2",
            "b2f4f938bc194baa9e2411895826a600",
            "81cfb45939ed4dc8845074083b271696",
            "8684cdaa79f441f58e3830ad98dae2ab",
            "1f2a60f184cc43b186b0a9ab4286868e",
            "bcc9e703f94b4510815b879bf6c00716",
            "d6d280a835c741f1803fdafe522c22ed",
            "592d676920fc4148a638cbf0af7d4e2d",
            "2f5cf935dc5245b2bb3e8d56645b73e1",
            "d1b8733c048f42c19de978f4c0497294",
            "def3a82c17e64f5ca374a140140036a4",
            "f4df4dd431e742dc8a985f67c9df273a",
            "159259beb3fd48f099eba5296cfe1253",
            "e121d4913a4544299a732ca19dccb263",
            "94b0eee34095414ca94b5029c1302263",
            "4e721a5376264382a48420e9007d3998",
            "ed79384fa61d4093bc76803b4dc6cfa1",
            "9ecb0c5cb5e1429f86de669e966b28d3"
          ]
        },
        "outputId": "1d0c5017-1e4e-4e96-a9ac-ed2fdd807f06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/851k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bd17df20df94f8691739e32587bfcd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c77122f70b94237b64c1e3b37b25eb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "592d676920fc4148a638cbf0af7d4e2d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "mbert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")"
      ],
      "id": "bfddbd7c"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "042ad78a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c952e32-9cec-4afd-bd7f-9b9c1c32ecc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thinking', 'machines']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "mbert_tokenizer.tokenize(\"thinking machines\")"
      ],
      "id": "042ad78a"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "deeed8c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb22438-f106-452e-b2fe-c26dc0d6d06e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['maquinas', 'de', 'pensar']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "mbert_tokenizer.tokenize(\"maquinas de pensar\")"
      ],
      "id": "deeed8c1"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3b7157dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c196bc6-4b96-45b3-a942-99756f55f74a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['स', '##ो', '##च', 'म', '##शी', '##न']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "mbert_tokenizer.tokenize(\"सोच मशीन\")"
      ],
      "id": "3b7157dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b20fe02a"
      },
      "source": [
        "As you can see mBERT's tokenizer works on different languages. We can similarly load a pretrained mbert model and feed data in different languages"
      ],
      "id": "b20fe02a"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d403c05e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "e0255e49523a42be872a13b15b50bb87",
            "eaa6e207d5df4fbb8ffb55c59b3a5027",
            "98255546fe1e4a70a1e2200bd39e9b5d",
            "15344f9efcae4a319b4fb6c0a1f92060",
            "eeaf347b027c41eab23bbcbdc74b93c9",
            "1c78338d90d4493092c73e24c34d0157",
            "cecb9de27f9e48a68100bc5c10e1a1b8",
            "e70d4fbf82da4411ba7e088f3704c222",
            "b3486d34bd3f443e9a2814248d3855d6",
            "77aed5a8df3141c8bc89980b5da52544",
            "188e1ca6e08143cbb06c282da423cde2"
          ]
        },
        "outputId": "2b387ad4-6dca-475b-de5c-f2c34ab69442"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/641M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0255e49523a42be872a13b15b50bb87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "mbert_model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")"
      ],
      "id": "d403c05e"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b63671ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c51109-b12a-4b69-9d29-145f7518959c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "mbert_model"
      ],
      "id": "b63671ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96bce87e"
      },
      "source": [
        "As you can see the architecture is identical to the original BERT model. The only thing that is different is the shape of word_embeddings which is 105879 X 768, meaning there are 105879 unique tokens supported by mBERT (uncased). In contrast BERT (uncased) supports 30522 tokens."
      ],
      "id": "96bce87e"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "edeb75d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f663a7-59e3-4e94-d462-7d79d975ea95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                               tensor([[[-0.0295,  0.0307,  0.0245,  ...,  0.0328, -0.0562,  0.0789],\n",
              "                                                        [ 0.2827,  0.4737, -0.1378,  ..., -0.1892,  0.1408, -0.3370],\n",
              "                                                        [ 0.1871,  0.6193,  0.1692,  ...,  0.0987, -0.0519, -0.0380],\n",
              "                                                        [-0.0354,  0.4805, -0.2533,  ...,  0.7390,  0.1286, -0.6764]]],\n",
              "                                                      grad_fn=<NativeLayerNormBackward0>)),\n",
              "                                              ('pooler_output',\n",
              "                                               tensor([[ 7.3179e-02,  1.0201e-01,  1.0094e-01,  9.1636e-02,  1.4111e-01,\n",
              "                                                         3.3841e-01,  9.0549e-02, -6.1101e-02, -1.3902e-01,  2.4607e-01,\n",
              "                                                        -1.7623e-01, -1.2388e-01,  1.7149e-01, -1.2340e-01, -1.6021e-01,\n",
              "                                                         2.9057e-02,  1.3472e-01,  7.6387e-02,  1.5949e-01,  4.8040e-02,\n",
              "                                                         3.7260e-02, -3.0617e-02,  5.3897e-02,  6.3597e-02,  2.1218e-01,\n",
              "                                                        -1.0945e-01,  2.1902e-01,  8.5052e-02,  2.2458e-01,  2.5002e-01,\n",
              "                                                         1.8784e-01,  1.9675e-01,  1.9028e-01, -6.7974e-02,  1.2689e-01,\n",
              "                                                        -5.0750e-02,  8.9531e-02,  7.3671e-02,  2.0277e-01,  4.1014e-02,\n",
              "                                                         1.2571e-01,  2.5094e-01,  9.7308e-02, -5.8275e-02, -3.0980e-01,\n",
              "                                                         9.3865e-02, -1.3890e-01, -6.5643e-02,  9.9998e-01,  1.3597e-01,\n",
              "                                                         7.1079e-02, -1.7904e-02,  4.0144e-02, -2.4498e-01,  2.1730e-01,\n",
              "                                                         9.9998e-01, -2.9374e-01, -2.0635e-01,  3.9283e-03, -1.2170e-01,\n",
              "                                                        -9.5930e-02,  5.2731e-02,  2.7847e-01,  6.3724e-02, -4.3806e-02,\n",
              "                                                         1.0382e-01, -4.0369e-02,  3.1189e-01,  5.5141e-02,  1.0137e-01,\n",
              "                                                         6.5947e-02, -5.4928e-02,  1.9506e-01,  2.7538e-01, -1.2576e-01,\n",
              "                                                        -3.4104e-02, -1.4140e-01, -9.4945e-02, -8.6547e-02,  1.5645e-01,\n",
              "                                                         1.0313e-01,  4.9405e-02, -2.0957e-01,  1.9060e-01,  2.2056e-02,\n",
              "                                                        -2.0124e-01, -1.5448e-01,  1.0537e-03,  9.0470e-02, -1.2185e-01,\n",
              "                                                         3.1289e-02, -6.4975e-02, -7.1926e-02, -9.2560e-02,  1.5431e-01,\n",
              "                                                        -1.1182e-01, -2.0971e-01,  2.2940e-02,  6.8358e-02, -2.0433e-01,\n",
              "                                                        -2.1997e-02,  1.1978e-01, -4.2444e-03,  1.4974e-01,  1.5300e-01,\n",
              "                                                         6.4774e-02, -1.8277e-01, -1.0238e-01,  6.4092e-02, -2.1379e-02,\n",
              "                                                        -2.0232e-01, -4.0598e-02,  3.0287e-01,  1.1264e-01,  4.2799e-02,\n",
              "                                                        -4.9957e-02, -1.6272e-01, -5.2993e-01,  2.4338e-02,  8.4274e-02,\n",
              "                                                        -7.2513e-02,  9.9998e-01, -8.1503e-02, -1.0315e-01,  1.0807e-01,\n",
              "                                                        -1.6528e-01, -7.4172e-02,  1.7210e-01, -1.7617e-01,  2.3838e-01,\n",
              "                                                        -2.4627e-01, -3.5075e-02, -2.0167e-01,  1.1083e-02, -2.1585e-01,\n",
              "                                                         1.9591e-01,  2.8572e-02, -1.3423e-01, -2.7209e-02, -1.9213e-01,\n",
              "                                                         4.5604e-02,  9.3544e-02,  9.3215e-02,  5.9238e-03,  1.4489e-01,\n",
              "                                                        -1.2675e-01, -8.2117e-02, -2.3945e-02,  5.8369e-02,  2.0040e-01,\n",
              "                                                        -2.7510e-01, -1.5230e-01, -6.6988e-02, -1.4324e-01,  4.8355e-02,\n",
              "                                                        -2.4482e-01,  6.4942e-02, -2.7865e-01,  1.9275e-01, -1.6717e-02,\n",
              "                                                        -2.0453e-01,  2.0115e-01,  2.0163e-01,  5.7708e-02,  1.0814e-01,\n",
              "                                                        -1.4691e-01,  5.0600e-01, -1.4347e-01,  1.4694e-01, -1.6047e-01,\n",
              "                                                         7.4324e-02,  5.1643e-02,  2.3387e-01,  1.5526e-01, -1.1582e-01,\n",
              "                                                        -2.3384e-01,  1.6088e-01, -1.5283e-02,  6.3142e-02, -2.9525e-01,\n",
              "                                                         1.7536e-02, -2.9049e-01, -8.7841e-02,  8.7400e-02,  7.3242e-02,\n",
              "                                                         4.4863e-03, -1.3267e-01, -4.5216e-01, -1.2429e-01, -1.5805e-01,\n",
              "                                                         1.1848e-01,  1.0525e-01,  8.2202e-02,  1.3625e-01,  1.3559e-01,\n",
              "                                                         9.6080e-02, -1.5444e-01, -1.3422e-01, -5.1552e-02,  3.8195e-02,\n",
              "                                                        -3.3402e-01, -2.0950e-02,  5.8303e-02, -1.1204e-01, -2.4186e-01,\n",
              "                                                         2.0704e-01, -1.0256e-01,  9.9998e-01,  1.1866e-01, -7.6897e-02,\n",
              "                                                         1.5445e-01, -4.3846e-02,  2.0678e-02,  1.4141e-02, -1.3867e-01,\n",
              "                                                         1.3031e-01,  1.3122e-01, -3.6650e-03,  1.0144e-01, -1.4299e-01,\n",
              "                                                        -1.6708e-01,  4.9734e-01,  2.1075e-01, -1.8210e-01, -1.5134e-02,\n",
              "                                                        -2.5535e-01, -5.7146e-02, -2.7071e-01,  8.0420e-02, -1.8984e-02,\n",
              "                                                         4.7518e-02,  1.2303e-01,  3.8837e-01, -2.0640e-01,  9.6626e-02,\n",
              "                                                        -2.8383e-01, -1.5654e-01, -1.9583e-01, -2.4416e-01, -1.3667e-01,\n",
              "                                                         6.2990e-02,  1.6517e-01, -9.4205e-02, -7.0088e-02,  2.2586e-01,\n",
              "                                                        -1.5455e-01,  6.8988e-02, -1.5306e-01, -1.4796e-01, -9.1485e-02,\n",
              "                                                         1.8129e-02, -8.6493e-03, -4.7684e-02,  2.5947e-01,  1.6200e-01,\n",
              "                                                         4.8667e-02, -7.7197e-02, -1.5778e-01,  2.4799e-02,  1.3296e-01,\n",
              "                                                         6.9303e-02,  9.7160e-03, -1.6599e-01, -1.1040e-01,  4.5165e-02,\n",
              "                                                        -1.8001e-01, -2.2770e-03,  1.8889e-02,  4.2017e-03,  7.3417e-02,\n",
              "                                                         1.2938e-01,  1.2569e-01, -5.7200e-02,  2.9756e-01, -3.4206e-01,\n",
              "                                                         9.0946e-02,  9.2744e-02, -2.3592e-01,  2.0424e-01,  1.3065e-01,\n",
              "                                                         5.1349e-02, -7.4663e-02,  5.8808e-03, -1.3135e-01,  2.5051e-02,\n",
              "                                                         1.7354e-01,  8.9000e-02, -1.2420e-01,  1.5896e-01,  2.4489e-01,\n",
              "                                                         6.5984e-02, -1.1487e-01, -7.8051e-02,  5.0933e-02,  1.4547e-01,\n",
              "                                                        -1.7255e-01,  2.7150e-01,  9.4294e-02, -1.1215e-01, -1.3279e-01,\n",
              "                                                         9.2363e-02, -1.3826e-01, -9.9183e-02,  1.7941e-02,  1.6031e-01,\n",
              "                                                         2.1074e-01, -1.6457e-01, -5.5598e-02, -1.2069e-01,  1.0693e-02,\n",
              "                                                         7.2653e-02, -6.5962e-02, -1.9477e-01,  2.1003e-01, -3.0987e-01,\n",
              "                                                         9.4053e-02,  1.9550e-01, -2.8578e-01, -7.0935e-03,  1.2259e-02,\n",
              "                                                         1.1221e-01,  9.9998e-01, -1.5399e-01, -1.5067e-01, -9.9998e-01,\n",
              "                                                        -4.0517e-01, -2.2675e-01,  2.4685e-01,  1.2637e-01, -2.0596e-01,\n",
              "                                                         9.4710e-03,  9.8535e-02, -1.5658e-01, -1.5616e-01,  1.1422e-01,\n",
              "                                                         3.4512e-01, -1.1153e-01,  9.7742e-02,  7.4420e-02,  1.6055e-02,\n",
              "                                                         9.3673e-02, -9.9997e-01,  1.3721e-02,  1.0505e-01,  4.5990e-02,\n",
              "                                                        -2.7098e-02, -1.7936e-01, -1.9624e-01, -7.5425e-02,  1.3567e-01,\n",
              "                                                         1.2713e-01,  1.2091e-01,  2.1556e-02, -1.5238e-01, -3.4905e-01,\n",
              "                                                         1.1866e-01, -5.9070e-02,  3.0714e-02, -1.7615e-01, -1.8791e-01,\n",
              "                                                         4.0728e-02,  1.5794e-01,  4.1043e-03,  2.5339e-01, -9.1826e-02,\n",
              "                                                         9.0279e-02, -1.4581e-01,  9.9998e-01,  1.3606e-01, -9.2719e-02,\n",
              "                                                         9.9998e-01,  2.4808e-01,  2.8235e-02, -3.3395e-01,  9.1213e-02,\n",
              "                                                         6.6393e-02,  9.9998e-01,  6.3202e-02, -1.9145e-01,  1.9956e-02,\n",
              "                                                        -8.7200e-02,  1.6400e-01,  3.1808e-01, -5.4950e-02, -9.9998e-01,\n",
              "                                                         3.9525e-02,  1.3308e-01,  8.9567e-02, -2.0165e-02,  9.9998e-01,\n",
              "                                                        -4.1042e-02, -9.1357e-02,  7.8819e-03,  2.8616e-01,  7.6935e-02,\n",
              "                                                         3.1532e-01,  1.8350e-01,  2.7013e-02, -1.6635e-01, -6.1900e-02,\n",
              "                                                        -7.2003e-02, -2.7173e-01, -1.1778e-01,  5.0166e-02, -6.7674e-02,\n",
              "                                                        -2.2937e-02, -1.5914e-01, -6.9601e-02,  2.1845e-02,  9.9998e-01,\n",
              "                                                        -5.6357e-02,  1.2465e-01,  5.5937e-02,  3.0309e-02,  8.3948e-02,\n",
              "                                                        -3.2562e-02,  9.1416e-02, -2.0855e-01,  2.4348e-01, -2.0648e-01,\n",
              "                                                         1.2498e-01, -2.9969e-02, -2.4256e-03, -1.8928e-01, -5.9992e-02,\n",
              "                                                        -1.8654e-01,  1.1466e-01,  3.2974e-02,  2.7450e-01,  9.8092e-02,\n",
              "                                                        -5.1888e-03, -4.1001e-02,  1.3183e-01,  3.1007e-04,  2.5039e-01,\n",
              "                                                        -1.2271e-01,  9.9998e-01,  1.4857e-01, -1.0520e-01,  4.4375e-02,\n",
              "                                                        -8.9653e-02, -1.6761e-01, -1.0846e-01, -2.6062e-01,  3.6854e-01,\n",
              "                                                         7.4351e-02,  1.4631e-01,  6.7138e-02,  2.0981e-01,  4.1744e-03,\n",
              "                                                        -8.7262e-02,  1.0625e-01,  4.5029e-02, -4.9726e-02, -1.6090e-01,\n",
              "                                                        -9.9999e-01, -2.4006e-01,  1.2973e-01, -1.7996e-01, -1.4771e-01,\n",
              "                                                         9.7282e-02, -2.4893e-01, -2.8951e-02, -1.0087e-01, -2.5671e-02,\n",
              "                                                         5.3566e-03, -1.7670e-01, -1.5131e-01,  7.0804e-02, -1.4243e-01,\n",
              "                                                        -1.8981e-01,  1.7267e-01,  1.5724e-01,  2.5108e-01,  3.8738e-02,\n",
              "                                                         2.4062e-01,  1.2826e-01, -1.4060e-02,  1.3581e-01, -2.5359e-02,\n",
              "                                                         2.8074e-03, -2.6812e-01, -2.8872e-01, -1.3352e-01, -1.5422e-01,\n",
              "                                                         1.3957e-01, -1.9933e-01,  3.8098e-02,  5.4995e-02, -1.1654e-01,\n",
              "                                                         2.3261e-01,  1.3446e-01,  4.0561e-02, -1.5145e-01,  2.4640e-02,\n",
              "                                                        -4.3278e-03,  6.3809e-02, -2.7966e-01,  1.8674e-01, -9.3060e-02,\n",
              "                                                         1.3904e-01, -3.1103e-02, -1.2904e-01,  1.3963e-01, -1.9823e-01,\n",
              "                                                         1.3823e-01,  1.3178e-01,  1.4865e-01, -4.3583e-02, -1.7827e-01,\n",
              "                                                        -2.8847e-02, -7.4495e-03,  2.0755e-01,  7.0420e-02, -8.1432e-02,\n",
              "                                                        -1.1339e-01, -7.5352e-02, -2.0457e-01,  3.9577e-02, -2.0638e-02,\n",
              "                                                        -9.9998e-01,  2.6041e-03, -1.4317e-01, -1.2968e-01,  1.6345e-01,\n",
              "                                                         1.3522e-02,  2.9230e-01, -7.4525e-02, -2.8082e-01,  2.1194e-01,\n",
              "                                                         4.2106e-03, -2.3653e-01, -5.0939e-02,  7.8465e-02,  8.5712e-03,\n",
              "                                                         4.9473e-02, -9.9998e-01, -2.4342e-02,  6.6554e-02, -1.9232e-01,\n",
              "                                                         1.0921e-01,  1.4569e-01, -3.5886e-02,  7.3304e-02, -6.5317e-02,\n",
              "                                                         6.8486e-01,  6.1876e-02,  8.5777e-02, -8.7385e-02, -8.7729e-02,\n",
              "                                                        -1.3302e-01, -1.5859e-01, -1.5562e-01,  1.6459e-01,  3.1978e-03,\n",
              "                                                         1.2600e-01, -1.6958e-01,  2.5404e-01,  4.9495e-02,  3.7814e-01,\n",
              "                                                         1.5938e-01, -7.9063e-02,  5.5768e-02, -5.4164e-02,  1.7684e-01,\n",
              "                                                         2.8788e-02,  2.4044e-01, -1.7441e-01,  7.5438e-02,  3.1538e-02,\n",
              "                                                        -1.3379e-01,  1.4529e-01,  1.6321e-01,  1.8002e-02,  2.7364e-01,\n",
              "                                                         1.0350e-01,  1.6075e-01, -6.0345e-02, -6.6107e-02,  1.5257e-02,\n",
              "                                                         5.3042e-02, -2.2797e-01,  2.5812e-02,  5.0953e-02,  6.9829e-02,\n",
              "                                                        -1.4106e-01,  1.0170e-01, -1.7497e-01,  6.7592e-02, -2.2314e-01,\n",
              "                                                        -1.6602e-01, -1.5866e-01,  5.3789e-02, -5.5261e-02, -1.7660e-01,\n",
              "                                                         1.8860e-01, -1.3061e-01, -2.0776e-01, -1.0591e-01,  4.6543e-02,\n",
              "                                                         9.5898e-02, -7.5416e-02, -2.9110e-02,  1.4028e-01,  2.0851e-01,\n",
              "                                                        -2.7833e-02,  1.4745e-01,  9.1486e-02, -5.3949e-02,  6.6658e-02,\n",
              "                                                         2.0588e-01, -1.2952e-01, -2.6022e-01,  1.8500e-01,  8.4620e-02,\n",
              "                                                         1.4916e-02,  1.7777e-01, -3.8061e-02, -2.3495e-01,  1.3902e-01,\n",
              "                                                         3.2566e-02, -4.0397e-02, -3.6005e-02,  1.2015e-01, -1.0909e-01,\n",
              "                                                        -8.8604e-02,  1.1901e-01, -9.9998e-01,  1.0674e-01, -8.9303e-02,\n",
              "                                                        -4.3718e-02,  2.6641e-01,  2.2693e-01,  1.5056e-01,  1.4210e-01,\n",
              "                                                         1.6559e-02, -2.3216e-01, -2.5339e-01, -1.7110e-02, -9.0951e-02,\n",
              "                                                        -3.2911e-01,  7.1875e-02, -1.3863e-01, -7.9049e-02,  1.5858e-01,\n",
              "                                                        -2.7387e-01, -1.9463e-01, -9.5768e-02, -6.6397e-02,  1.5667e-01,\n",
              "                                                         8.5604e-02,  3.7492e-03, -1.7165e-01, -6.4464e-02,  4.7901e-02,\n",
              "                                                        -2.8880e-01, -2.5597e-01,  2.0448e-01,  2.2661e-01,  1.8551e-01,\n",
              "                                                        -4.0198e-01,  1.8714e-01, -1.2346e-01, -6.3954e-02,  5.8401e-03,\n",
              "                                                         1.6813e-01,  7.9842e-04, -1.1464e-01,  2.6567e-01, -1.1165e-01,\n",
              "                                                        -2.1061e-01,  6.7415e-02, -2.5445e-01,  1.1992e-01, -6.3134e-01,\n",
              "                                                         1.9971e-01,  9.3713e-02,  3.0368e-01, -1.5028e-01,  2.2328e-01,\n",
              "                                                         8.5728e-02,  4.6135e-02,  5.7843e-03,  1.4339e-01, -7.3669e-03,\n",
              "                                                         2.8754e-01, -3.1202e-02,  2.2612e-01,  3.4620e-01, -9.9998e-01,\n",
              "                                                        -3.6616e-02, -5.4562e-02, -1.5097e-01, -9.9998e-01, -8.8908e-02,\n",
              "                                                         1.2939e-01,  5.8688e-02,  1.5712e-01,  5.9310e-02,  1.4333e-01,\n",
              "                                                         1.9591e-01, -1.4970e-01, -1.1364e-01,  1.6807e-01, -1.9834e-01,\n",
              "                                                        -5.9953e-02,  1.9273e-01, -1.3947e-01, -1.7666e-01,  1.1213e-01,\n",
              "                                                         1.8712e-01,  1.6260e-01,  7.3317e-02, -2.6980e-01,  4.3758e-01,\n",
              "                                                        -8.4492e-02, -4.7005e-02, -3.3171e-01, -1.0506e-01,  2.1018e-01,\n",
              "                                                        -6.6405e-02,  5.1141e-02,  1.3922e-01,  2.2156e-01, -8.6738e-02,\n",
              "                                                        -1.8886e-01, -5.7752e-02, -8.9208e-02,  2.6356e-01,  9.5995e-02,\n",
              "                                                         1.1035e-01, -2.0700e-02,  2.8573e-01, -1.5227e-01, -6.7774e-02,\n",
              "                                                        -1.2150e-03, -3.9227e-03,  2.1186e-01, -1.6579e-01, -1.0625e-01,\n",
              "                                                         3.1726e-01, -1.9441e-01, -8.0780e-02,  1.5680e-01,  1.2033e-01,\n",
              "                                                        -1.8308e-01, -6.0178e-02, -9.5076e-02,  2.9383e-01, -9.9998e-01,\n",
              "                                                        -1.3483e-02, -5.7824e-02,  1.3638e-01,  1.1943e-02, -9.4663e-02,\n",
              "                                                         6.3522e-01,  2.0999e-01, -8.0715e-03,  2.4701e-01, -2.1165e-01,\n",
              "                                                        -8.7867e-02, -1.8082e-01,  1.1048e-01,  4.5320e-02, -9.6414e-03,\n",
              "                                                         1.1225e-02, -1.1681e-01, -1.1469e-01]], grad_fn=<TanhBackward0>))])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#@title Default title text\n",
        "en_sent = \"thinking machines\"\n",
        "tokenizer_output = mbert_tokenizer(en_sent, return_tensors=\"pt\")\n",
        "input_ids, attn_mask = tokenizer_output[\"input_ids\"], tokenizer_output[\"attention_mask\"]\n",
        "\n",
        "mbert_model(input_ids, attention_mask = attn_mask)"
      ],
      "id": "edeb75d8"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "829a3a77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3470caf-5c4c-40bd-9173-d00d5f98e66e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                               tensor([[[-0.0657, -0.0614,  0.0060,  ..., -0.0240, -0.0420, -0.0673],\n",
              "                                                        [ 0.2430,  0.5252, -0.0694,  ..., -0.0108,  0.5518, -0.4204],\n",
              "                                                        [-0.2587, -0.2086,  0.1115,  ..., -0.7734,  0.1412, -0.9133],\n",
              "                                                        [-0.1032,  0.7808,  0.1022,  ...,  0.0870,  0.1456, -0.5586],\n",
              "                                                        [-0.0765,  0.3234, -0.2513,  ...,  0.3950,  0.2862, -1.1907]]],\n",
              "                                                      grad_fn=<NativeLayerNormBackward0>)),\n",
              "                                              ('pooler_output',\n",
              "                                               tensor([[ 1.4176e-01,  3.4401e-02,  1.5948e-01,  1.7631e-01,  1.8552e-01,\n",
              "                                                         4.2113e-01,  1.4076e-01, -1.4554e-01, -1.7636e-01,  2.9590e-01,\n",
              "                                                        -1.8210e-01, -2.1683e-01,  2.2756e-01, -1.7093e-01, -1.8114e-01,\n",
              "                                                         5.4472e-02,  1.9600e-01,  1.2176e-01,  2.0155e-01,  1.3893e-01,\n",
              "                                                        -4.2202e-02, -8.1407e-02,  8.8412e-02, -1.3793e-02,  2.7080e-01,\n",
              "                                                        -1.6806e-01,  2.6696e-01,  1.2918e-01,  3.6292e-01,  2.9422e-01,\n",
              "                                                         2.0838e-01,  2.5432e-01,  2.5948e-01, -1.1543e-01,  2.1006e-01,\n",
              "                                                         2.0638e-02,  3.6320e-02,  1.2488e-01,  2.3027e-01,  8.2570e-02,\n",
              "                                                         1.4708e-01,  4.4298e-01,  1.5398e-01, -1.5360e-01, -3.4018e-01,\n",
              "                                                         2.2819e-01, -1.9345e-01, -8.5304e-02,  9.9999e-01,  1.9508e-01,\n",
              "                                                         8.9446e-02, -1.4110e-01,  1.0632e-01, -2.7657e-01,  2.4497e-01,\n",
              "                                                         9.9999e-01, -3.4471e-01, -2.3381e-01,  5.2617e-02, -1.3738e-01,\n",
              "                                                        -2.0170e-01,  7.5959e-02,  3.1516e-01,  1.3019e-01, -1.1624e-01,\n",
              "                                                         1.2369e-01, -6.2276e-02,  3.3121e-01,  1.2949e-02,  1.1194e-01,\n",
              "                                                         1.0270e-01, -1.0232e-01,  2.2664e-01,  3.0402e-01, -1.8597e-01,\n",
              "                                                         4.0614e-02, -2.0928e-01, -2.0389e-01, -1.9426e-01,  1.9920e-01,\n",
              "                                                         1.9141e-01,  8.9631e-02, -2.5999e-01,  2.3049e-01, -9.8978e-02,\n",
              "                                                        -2.9516e-01, -2.1329e-01, -7.9474e-02,  1.3188e-01, -2.2406e-01,\n",
              "                                                         9.4448e-02, -1.0134e-01, -9.9620e-02, -1.3253e-01,  1.6258e-01,\n",
              "                                                        -1.6331e-01, -2.5396e-01, -7.3900e-02,  1.3007e-01, -2.8521e-01,\n",
              "                                                        -5.7481e-02,  1.6074e-01,  4.0952e-02,  1.1781e-01,  2.0784e-01,\n",
              "                                                         2.3460e-01, -2.5248e-01, -1.3074e-01, -1.0675e-02, -9.2083e-03,\n",
              "                                                        -2.2128e-01,  4.4169e-02,  4.5098e-01,  2.1983e-01,  8.7659e-02,\n",
              "                                                         2.7385e-02, -1.8454e-01, -7.4264e-01, -5.1756e-02,  1.4141e-01,\n",
              "                                                        -3.4279e-02,  9.9999e-01, -1.6274e-01, -1.8138e-01,  1.5650e-01,\n",
              "                                                        -2.6184e-01, -8.8531e-02,  2.2055e-01, -2.1966e-01,  3.1545e-01,\n",
              "                                                        -2.9460e-01, -8.4367e-02, -2.5458e-01,  4.0762e-02, -2.7454e-01,\n",
              "                                                         2.8245e-01,  8.0520e-02, -1.1288e-01,  5.4163e-02, -2.4504e-01,\n",
              "                                                         7.4325e-02,  1.4228e-01,  1.4912e-01,  1.3070e-01,  1.9802e-01,\n",
              "                                                        -1.9757e-01, -9.4446e-02,  1.2255e-02, -4.4503e-02,  2.2847e-01,\n",
              "                                                        -3.0940e-01, -2.4367e-01, -3.6847e-02, -1.9609e-01,  4.9528e-03,\n",
              "                                                        -3.1056e-01,  1.1333e-01, -3.2450e-01,  2.2749e-01,  7.3080e-02,\n",
              "                                                        -2.3836e-01,  2.3000e-01,  2.5693e-01,  1.3141e-01,  1.7909e-01,\n",
              "                                                        -1.7676e-01,  7.1778e-01, -1.9316e-01,  2.4662e-01, -2.3022e-01,\n",
              "                                                        -7.1705e-02,  1.1786e-01,  2.7383e-01,  1.9487e-01, -1.4186e-01,\n",
              "                                                        -2.8495e-01,  2.0092e-01, -7.7067e-02,  1.3877e-01, -4.7296e-01,\n",
              "                                                         7.2584e-02, -3.7574e-01, -1.2160e-01,  1.4101e-01,  3.9108e-02,\n",
              "                                                         4.1496e-02, -2.3796e-01, -6.5369e-01, -4.6147e-02, -2.4818e-01,\n",
              "                                                         1.7878e-01,  1.8163e-01,  1.3553e-01,  2.3442e-01,  1.8634e-01,\n",
              "                                                        -1.0071e-02, -1.9418e-01, -2.2230e-01, -7.7779e-02,  1.1157e-01,\n",
              "                                                        -4.3845e-01,  4.1401e-02, -5.1808e-02, -1.6167e-01, -2.8458e-01,\n",
              "                                                         2.7338e-01, -1.7314e-01,  9.9999e-01,  6.0498e-02, -1.6026e-01,\n",
              "                                                         1.6814e-01, -1.4584e-01, -5.7390e-02, -5.6743e-02, -2.1679e-01,\n",
              "                                                         1.5827e-01,  1.6530e-01, -8.8480e-02,  1.8519e-01, -2.3680e-01,\n",
              "                                                        -2.3501e-01,  6.7256e-01,  2.8943e-01, -2.2693e-01, -6.8995e-02,\n",
              "                                                        -2.8145e-01, -1.9822e-02, -3.4394e-01,  2.2847e-01, -1.2438e-01,\n",
              "                                                         8.7177e-02,  1.5882e-01,  4.0037e-01, -2.5549e-01,  1.4033e-01,\n",
              "                                                        -3.3692e-01, -2.1416e-01, -2.2396e-01, -4.0181e-01, -2.0030e-01,\n",
              "                                                         1.0835e-01,  1.6841e-01, -1.4286e-01, -5.5853e-02,  2.6443e-01,\n",
              "                                                        -2.0406e-01,  1.3307e-01, -2.1589e-01, -2.5919e-01, -1.5416e-01,\n",
              "                                                         4.1412e-02, -1.3100e-01, -1.1098e-01,  2.7552e-01,  1.8748e-01,\n",
              "                                                         1.2460e-01, -1.0504e-01, -1.6342e-01,  8.9278e-02,  1.9794e-01,\n",
              "                                                         1.5078e-01,  3.2019e-02, -2.2913e-01, -1.0459e-01, -1.0096e-02,\n",
              "                                                        -2.5375e-01,  6.5590e-02,  6.1361e-02, -1.2471e-01,  1.0422e-01,\n",
              "                                                         3.1563e-01,  2.0883e-01, -1.0141e-01,  3.4946e-01, -4.2757e-01,\n",
              "                                                         1.1210e-01,  1.7992e-01, -2.4741e-01,  2.5516e-01,  1.5931e-01,\n",
              "                                                        -1.8456e-02, -1.2316e-01,  7.8277e-02, -1.6251e-01,  7.2417e-02,\n",
              "                                                         2.2503e-01,  1.5575e-01, -1.6483e-01,  1.4196e-01,  3.0710e-01,\n",
              "                                                         1.3345e-01, -1.7176e-01, -1.1518e-01,  1.4071e-01,  2.1860e-01,\n",
              "                                                        -2.0527e-01,  3.1394e-01,  1.8230e-01, -1.8522e-01, -1.5367e-01,\n",
              "                                                         1.1750e-01, -1.9448e-01, -1.7304e-01, -5.1064e-02,  2.6404e-01,\n",
              "                                                         2.3060e-01, -2.1061e-01, -1.2781e-01, -2.0407e-01, -4.5289e-02,\n",
              "                                                         8.3658e-02, -1.5178e-01, -2.6070e-01,  2.2416e-01, -3.5798e-01,\n",
              "                                                         1.1783e-01,  2.2576e-01, -3.2027e-01, -5.1004e-02, -5.5694e-02,\n",
              "                                                         1.8284e-01,  9.9999e-01, -2.1127e-01, -1.3878e-01, -9.9999e-01,\n",
              "                                                        -4.6576e-01, -2.9456e-01,  2.7522e-01,  1.6385e-01, -2.7458e-01,\n",
              "                                                        -7.8472e-02,  1.3114e-01, -1.9779e-01, -2.3622e-01,  2.1868e-01,\n",
              "                                                         3.8457e-01, -1.8298e-01,  1.2252e-01,  1.0747e-01,  2.9732e-02,\n",
              "                                                         1.2897e-01, -9.9998e-01, -4.7202e-02,  1.3700e-02, -3.2895e-02,\n",
              "                                                        -7.5726e-02, -2.2144e-01, -2.1903e-01, -1.2936e-01,  1.8736e-01,\n",
              "                                                         1.9446e-01,  1.7180e-01, -7.0668e-02, -2.5061e-01, -3.4393e-01,\n",
              "                                                         1.5563e-01, -1.3025e-01,  6.0536e-02, -2.0935e-01, -2.5558e-01,\n",
              "                                                         1.0602e-01,  2.3848e-01,  1.9070e-02,  2.9148e-01, -1.4300e-01,\n",
              "                                                         1.8768e-01, -2.1562e-01,  9.9999e-01,  2.1174e-01, -1.7241e-01,\n",
              "                                                         9.9999e-01,  2.9368e-01, -2.0803e-02, -4.4702e-01,  1.0769e-01,\n",
              "                                                         1.0370e-01,  9.9999e-01,  1.5182e-01, -2.5394e-01, -8.5451e-02,\n",
              "                                                         4.6755e-02,  2.4464e-01,  3.8935e-01, -5.4863e-03, -9.9999e-01,\n",
              "                                                         1.0994e-01,  1.7869e-01,  3.3433e-03, -4.7390e-02,  9.9999e-01,\n",
              "                                                        -9.2318e-02, -1.8041e-01,  7.8401e-02,  3.1596e-01,  1.4380e-01,\n",
              "                                                         3.7415e-01,  1.8647e-01, -2.8230e-02, -2.3531e-01, -9.2129e-02,\n",
              "                                                        -1.3040e-01, -3.2820e-01, -1.7585e-01,  1.0518e-01, -1.1582e-01,\n",
              "                                                        -1.0651e-01, -2.4714e-01,  1.1307e-02, -5.5399e-02,  9.9999e-01,\n",
              "                                                        -2.4822e-02,  1.9087e-01,  6.9512e-02,  1.3101e-01,  1.0372e-01,\n",
              "                                                        -7.8402e-02, -1.4170e-02, -2.8408e-01,  2.8636e-01, -2.6532e-01,\n",
              "                                                         1.8592e-01,  7.6087e-02,  5.1574e-02, -2.3418e-01, -1.0005e-01,\n",
              "                                                        -2.0759e-01,  1.8586e-01,  6.1952e-02,  4.4869e-01,  1.5651e-01,\n",
              "                                                        -9.8914e-02, -1.2176e-01,  1.8979e-01, -2.7777e-02,  2.8522e-01,\n",
              "                                                        -1.6327e-01,  9.9999e-01,  2.0271e-01, -1.7230e-01, -9.5023e-03,\n",
              "                                                        -1.1205e-01, -2.2409e-01, -1.8732e-01, -2.7898e-01,  5.4942e-01,\n",
              "                                                         1.3951e-01,  9.7582e-02,  1.6390e-01,  2.6419e-01, -7.2977e-02,\n",
              "                                                        -9.9677e-02,  1.4631e-01,  3.5513e-02,  7.0371e-03, -2.9917e-01,\n",
              "                                                        -9.9999e-01, -2.7512e-01,  1.8115e-01, -3.4174e-01, -2.1146e-01,\n",
              "                                                         3.7808e-02, -3.2011e-01, -8.5779e-02, -3.9099e-02,  8.2518e-03,\n",
              "                                                         8.7735e-02, -2.5740e-01, -2.0243e-01,  1.1256e-01, -1.3412e-01,\n",
              "                                                        -2.1730e-01,  1.9210e-01,  2.7734e-01,  2.7189e-01, -9.4020e-02,\n",
              "                                                         2.7952e-01,  1.8280e-01,  1.1657e-02,  2.1934e-01, -7.1974e-02,\n",
              "                                                         6.1104e-02, -3.5227e-01, -3.3142e-01, -1.9634e-01, -1.9735e-01,\n",
              "                                                         2.0644e-01, -2.4785e-01, -3.3867e-02,  1.2497e-01, -1.9365e-01,\n",
              "                                                         2.6553e-01,  1.8153e-01,  8.9658e-03, -1.6964e-01,  8.8955e-02,\n",
              "                                                        -6.2141e-02,  1.4524e-01, -3.3219e-01,  2.3616e-01, -1.8622e-02,\n",
              "                                                         2.2127e-01, -1.5129e-01, -6.2764e-02,  1.9729e-01, -2.5878e-01,\n",
              "                                                         1.7096e-01,  1.6829e-01,  1.9079e-01, -1.1256e-01, -2.2692e-01,\n",
              "                                                         9.4886e-04,  3.8270e-02,  2.4418e-01,  1.2216e-01, -1.7033e-01,\n",
              "                                                        -1.5731e-01, -1.6348e-01, -2.3694e-01, -3.7750e-04,  5.7342e-02,\n",
              "                                                        -9.9999e-01, -6.2483e-02, -1.4103e-01, -1.9935e-01,  2.1452e-01,\n",
              "                                                         1.0831e-01,  3.4353e-01, -6.4320e-02, -4.8609e-01,  2.9674e-01,\n",
              "                                                        -7.2625e-02, -2.7103e-01, -4.3679e-02,  1.3353e-01, -5.0690e-02,\n",
              "                                                         5.9567e-02, -9.9999e-01,  4.1516e-02,  1.8530e-01, -2.1969e-01,\n",
              "                                                         1.4529e-01,  1.9153e-01, -1.0433e-01,  1.0763e-01, -8.1715e-02,\n",
              "                                                         8.5897e-01,  8.7412e-02,  1.0658e-01, -1.1136e-01, -3.6795e-03,\n",
              "                                                        -1.7956e-01, -2.8567e-01, -1.8426e-01,  1.7989e-01, -8.2679e-03,\n",
              "                                                         1.4666e-01, -2.3866e-01,  2.7470e-01,  8.0881e-02,  4.1714e-01,\n",
              "                                                         1.9624e-01, -7.9879e-02,  6.6923e-02, -1.3577e-01,  2.4110e-01,\n",
              "                                                         5.0170e-02,  2.7440e-01, -1.0605e-01,  1.7907e-02,  1.4192e-01,\n",
              "                                                        -1.9542e-01,  1.7607e-01,  1.6831e-01,  8.5068e-02,  3.2943e-01,\n",
              "                                                         2.0415e-01,  2.2167e-01, -1.0445e-01, -1.1645e-01,  1.0808e-01,\n",
              "                                                         1.1252e-01, -2.6779e-01,  5.5929e-02,  1.6692e-01,  3.4567e-02,\n",
              "                                                        -6.8955e-02,  9.7206e-02, -2.1742e-01,  1.2839e-01, -2.3346e-01,\n",
              "                                                        -2.0766e-01, -2.3677e-01,  1.1460e-01, -1.0576e-01, -2.5598e-01,\n",
              "                                                         2.5922e-01, -1.7811e-01, -2.4270e-01, -1.0195e-01, -4.3534e-02,\n",
              "                                                         2.1582e-01, -1.4364e-01, -7.8588e-02,  1.8210e-01,  2.7148e-01,\n",
              "                                                         6.4059e-02,  2.2729e-01,  1.4698e-01, -1.0750e-01,  5.3824e-02,\n",
              "                                                         1.9585e-01, -2.0472e-01, -3.1686e-01,  2.0575e-01,  1.4279e-01,\n",
              "                                                         7.3550e-02,  1.9425e-01,  1.9031e-02, -2.7806e-01,  1.7672e-01,\n",
              "                                                         8.6702e-02, -5.5433e-02, -1.4306e-01,  1.4652e-01, -1.5505e-01,\n",
              "                                                        -9.4883e-02,  1.9275e-01, -9.9999e-01,  7.2696e-02, -1.1300e-01,\n",
              "                                                        -1.3813e-01,  3.3507e-01,  2.6896e-01,  1.7496e-01,  2.0019e-01,\n",
              "                                                        -8.8430e-03, -2.8412e-01, -2.7504e-01, -6.9042e-02, -5.6403e-02,\n",
              "                                                        -5.0014e-01,  1.2411e-01, -1.8666e-02, -8.8522e-02,  1.5650e-01,\n",
              "                                                        -4.0721e-01, -2.3049e-01, -1.5754e-01, -8.8076e-02,  2.1587e-01,\n",
              "                                                         1.3142e-01,  6.6759e-02, -3.6864e-01, -1.3832e-01, -1.4163e-02,\n",
              "                                                        -3.2093e-01, -2.9088e-01,  2.3202e-01,  2.5552e-01,  2.6093e-01,\n",
              "                                                        -5.5880e-01,  2.3389e-01, -2.1585e-01, -1.0226e-01,  4.9435e-02,\n",
              "                                                         1.6739e-01,  6.9797e-02, -1.2943e-01,  3.1545e-01, -1.4997e-01,\n",
              "                                                        -2.1408e-01,  1.0682e-01, -3.2121e-01,  1.3959e-01, -8.3104e-01,\n",
              "                                                         2.2084e-01,  1.2266e-01,  3.7062e-01, -2.3118e-01,  2.3138e-01,\n",
              "                                                         1.2532e-01,  1.1596e-01,  6.0222e-02,  1.9363e-01,  3.7853e-02,\n",
              "                                                         3.1746e-01, -8.0982e-02,  2.6098e-01,  3.9145e-01, -9.9999e-01,\n",
              "                                                        -7.6867e-02, -9.7705e-02, -1.9425e-01, -9.9999e-01, -1.6877e-01,\n",
              "                                                         1.6510e-01,  1.0897e-01,  1.8924e-01,  1.5639e-02,  2.1436e-01,\n",
              "                                                         2.6258e-01, -2.0205e-01, -1.9933e-01,  2.1862e-01, -2.7635e-01,\n",
              "                                                        -2.1669e-02,  2.4839e-01, -2.1092e-01, -1.9723e-01,  1.4701e-01,\n",
              "                                                         3.0229e-01,  3.7635e-01, -1.4870e-02, -4.7076e-01,  4.4111e-01,\n",
              "                                                        -1.0094e-01, -9.4811e-02, -4.3551e-01, -1.5859e-01,  2.5735e-01,\n",
              "                                                        -1.3036e-02,  1.0823e-01,  1.4470e-01,  3.0342e-01, -9.2594e-02,\n",
              "                                                        -2.0271e-01,  4.7906e-02, -1.3411e-01,  3.1351e-01,  1.6065e-01,\n",
              "                                                         1.6702e-01, -7.7265e-02,  4.4583e-01, -2.3032e-01, -1.3456e-01,\n",
              "                                                         4.6926e-02, -6.6956e-02,  3.8225e-01, -1.8512e-01, -1.9204e-01,\n",
              "                                                         3.7974e-01, -2.1666e-01, -6.7088e-02,  2.1756e-01,  1.3400e-01,\n",
              "                                                        -2.4468e-01, -1.2421e-01, -1.3409e-01,  3.2119e-01, -9.9999e-01,\n",
              "                                                        -5.9038e-02, -1.2530e-01,  2.2247e-01,  5.1446e-02, -1.5484e-01,\n",
              "                                                         8.1418e-01,  3.5868e-01,  3.3257e-02,  3.1401e-01, -2.9680e-01,\n",
              "                                                        -1.2265e-01, -2.9195e-01,  1.5110e-01,  8.8186e-02, -4.4364e-02,\n",
              "                                                         3.3199e-02, -1.5291e-01, -1.7318e-01]], grad_fn=<TanhBackward0>))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "es_sent = \"maquinas de pensar\"\n",
        "tokenizer_output = mbert_tokenizer(es_sent, return_tensors=\"pt\")\n",
        "input_ids, attn_mask = tokenizer_output[\"input_ids\"], tokenizer_output[\"attention_mask\"]\n",
        "\n",
        "mbert_model(input_ids, attention_mask = attn_mask)"
      ],
      "id": "829a3a77"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6b0d2bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19108b4-fe8a-4ed1-b8f2-d05df9c001bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                               tensor([[[-0.0183,  0.0577,  0.1038,  ..., -0.0349, -0.0897, -0.0034],\n",
              "                                                        [-0.2319,  0.0178, -0.0228,  ..., -0.4928,  0.1712, -0.3489],\n",
              "                                                        [-0.1214,  0.0804,  0.2790,  ..., -0.0647, -0.2073, -0.6718],\n",
              "                                                        ...,\n",
              "                                                        [-0.0835,  0.4992, -0.1798,  ...,  0.5467, -0.4407,  0.0024],\n",
              "                                                        [ 0.1764,  0.7496,  0.2607,  ...,  0.2637, -0.2617, -0.2716],\n",
              "                                                        [-0.3781,  0.5859,  0.2654,  ...,  0.3965, -0.5680, -0.8965]]],\n",
              "                                                      grad_fn=<NativeLayerNormBackward0>)),\n",
              "                                              ('pooler_output',\n",
              "                                               tensor([[ 1.9663e-01,  3.6831e-02,  1.9092e-01,  1.6675e-01,  2.1876e-01,\n",
              "                                                         4.5212e-01,  1.5738e-01, -1.8443e-01, -1.9007e-01,  2.7668e-01,\n",
              "                                                        -2.6375e-01, -2.2846e-01,  2.6193e-01, -1.7115e-01, -2.4437e-01,\n",
              "                                                         5.3468e-02,  1.8985e-01,  1.4454e-01,  2.6989e-01,  1.0231e-01,\n",
              "                                                        -7.4351e-02, -1.1409e-01,  1.3042e-01, -5.6443e-02,  3.0324e-01,\n",
              "                                                        -1.6460e-01,  2.7847e-01,  1.3497e-01,  4.5047e-01,  2.9605e-01,\n",
              "                                                         2.5428e-01,  2.3158e-01,  2.5374e-01, -7.5846e-02,  2.3163e-01,\n",
              "                                                         5.5427e-02,  1.1144e-02,  1.2426e-01,  2.6061e-01,  5.3806e-02,\n",
              "                                                         1.6303e-01,  5.1142e-01,  1.3269e-01, -1.3358e-01, -3.7102e-01,\n",
              "                                                         2.4315e-01, -1.8334e-01, -1.0740e-01,  9.9999e-01,  2.0407e-01,\n",
              "                                                         1.4211e-01, -2.0426e-01,  1.3370e-01, -3.2816e-01,  2.5923e-01,\n",
              "                                                         9.9999e-01, -3.7073e-01, -2.9902e-01,  4.3326e-02, -1.4992e-01,\n",
              "                                                        -2.3615e-01,  4.2202e-02,  3.4740e-01,  1.3696e-01, -1.5259e-01,\n",
              "                                                         7.5456e-02, -1.1221e-01,  3.4851e-01, -1.9165e-03,  9.3484e-02,\n",
              "                                                         9.4926e-02, -1.3147e-01,  2.1034e-01,  3.0040e-01, -1.8503e-01,\n",
              "                                                         8.6255e-02, -2.2896e-01, -1.7900e-01, -1.6472e-01,  1.9012e-01,\n",
              "                                                         2.1268e-01,  8.2321e-02, -2.9702e-01,  2.2585e-01, -1.8244e-01,\n",
              "                                                        -3.2864e-01, -2.8098e-01, -1.1694e-01,  1.7625e-01, -1.6935e-01,\n",
              "                                                         1.3944e-01, -1.1736e-01, -1.0675e-01, -1.4355e-01,  1.8238e-01,\n",
              "                                                        -1.6324e-01, -2.8235e-01, -8.2830e-02,  1.2819e-01, -2.6289e-01,\n",
              "                                                        -6.9057e-02,  1.9388e-01,  5.7897e-02,  4.5263e-02,  2.4417e-01,\n",
              "                                                         3.3384e-01, -2.9188e-01, -1.8632e-01, -1.7193e-02,  3.4798e-02,\n",
              "                                                        -2.2559e-01,  6.8057e-02,  4.9111e-01,  2.5987e-01,  8.5137e-02,\n",
              "                                                         3.2450e-02, -2.2121e-01, -8.0889e-01, -5.7206e-02,  1.3427e-01,\n",
              "                                                        -3.2190e-02,  9.9999e-01, -1.4184e-01, -1.3690e-01,  1.4644e-01,\n",
              "                                                        -2.6983e-01, -1.7826e-01,  2.4423e-01, -2.3707e-01,  3.6375e-01,\n",
              "                                                        -2.6699e-01, -5.4524e-02, -2.4615e-01,  6.7699e-02, -2.5381e-01,\n",
              "                                                         2.7254e-01,  1.0355e-01, -1.3467e-01,  9.7743e-02, -2.7196e-01,\n",
              "                                                         9.0038e-02,  1.4215e-01,  1.5558e-01,  1.3703e-01,  2.3534e-01,\n",
              "                                                        -2.5741e-01, -1.3028e-01, -2.0319e-03, -1.0056e-01,  2.3707e-01,\n",
              "                                                        -3.5124e-01, -2.5083e-01,  6.5748e-02, -2.3660e-01, -2.3105e-02,\n",
              "                                                        -3.2675e-01,  1.5743e-01, -3.0924e-01,  2.4876e-01,  7.8535e-02,\n",
              "                                                        -2.4270e-01,  2.4242e-01,  2.6871e-01,  1.9807e-01,  2.2575e-01,\n",
              "                                                        -2.0163e-01,  8.1418e-01, -1.9489e-01,  2.1186e-01, -2.8169e-01,\n",
              "                                                        -1.1333e-01,  1.4982e-01,  2.7974e-01,  1.9777e-01, -2.0505e-01,\n",
              "                                                        -2.9175e-01,  2.1200e-01, -7.9246e-02,  1.5474e-01, -5.4317e-01,\n",
              "                                                         1.4153e-01, -4.0566e-01, -1.5925e-01,  1.1928e-01, -2.3556e-02,\n",
              "                                                         4.5854e-02, -2.6647e-01, -7.1401e-01, -5.5387e-02, -2.4340e-01,\n",
              "                                                         1.5323e-01,  1.7945e-01,  1.5285e-01,  2.4550e-01,  2.0081e-01,\n",
              "                                                        -1.9869e-02, -2.2867e-01, -2.0114e-01, -5.2901e-02,  1.0954e-01,\n",
              "                                                        -5.2247e-01,  1.4260e-01, -3.7693e-02, -1.9527e-01, -2.8998e-01,\n",
              "                                                         2.6884e-01, -2.0809e-01,  9.9999e-01,  1.5934e-02, -2.1602e-01,\n",
              "                                                         1.5476e-01, -1.4760e-01, -4.4385e-02, -1.3111e-01, -2.0028e-01,\n",
              "                                                         1.5662e-01,  1.7127e-01, -1.2768e-01,  1.9116e-01, -2.7243e-01,\n",
              "                                                        -2.4477e-01,  7.5690e-01,  2.9928e-01, -2.4304e-01, -7.6691e-02,\n",
              "                                                        -2.8176e-01,  1.3389e-02, -3.0895e-01,  2.9156e-01, -1.8190e-01,\n",
              "                                                         9.0539e-02,  1.6665e-01,  4.5462e-01, -2.4566e-01,  1.6648e-01,\n",
              "                                                        -3.3514e-01, -2.4303e-01, -2.3925e-01, -5.1180e-01, -2.0440e-01,\n",
              "                                                         1.1086e-01,  1.6733e-01, -1.5439e-01, -4.0740e-02,  2.7723e-01,\n",
              "                                                        -2.0302e-01,  1.2149e-01, -2.1369e-01, -2.8728e-01, -1.8188e-01,\n",
              "                                                         8.6878e-02, -8.6058e-02, -1.3908e-01,  3.3000e-01,  1.6924e-01,\n",
              "                                                         1.4972e-01, -1.1761e-01, -1.9778e-01,  6.8015e-02,  2.0811e-01,\n",
              "                                                         2.1961e-01,  6.7246e-02, -1.9363e-01, -1.3662e-01, -6.5474e-03,\n",
              "                                                        -2.7672e-01,  1.5963e-01,  6.3441e-02, -1.3053e-01,  1.3130e-01,\n",
              "                                                         4.3404e-01,  1.9479e-01, -1.0431e-01,  3.6378e-01, -4.8233e-01,\n",
              "                                                         1.4847e-01,  2.2081e-01, -2.5962e-01,  2.7266e-01,  1.7587e-01,\n",
              "                                                        -4.5138e-02, -1.4823e-01,  7.9432e-02, -2.1471e-01,  8.0764e-02,\n",
              "                                                         2.2730e-01,  1.0793e-01, -1.8070e-01,  1.6334e-01,  3.5029e-01,\n",
              "                                                         1.6779e-01, -2.1697e-01, -1.6407e-01,  1.2461e-01,  2.0277e-01,\n",
              "                                                        -2.6040e-01,  3.4569e-01,  1.7667e-01, -1.8150e-01, -1.9666e-01,\n",
              "                                                         1.5590e-01, -1.9236e-01, -1.9151e-01, -1.7017e-04,  2.1024e-01,\n",
              "                                                         2.8650e-01, -1.9690e-01, -9.7160e-02, -2.0327e-01, -1.0787e-01,\n",
              "                                                         9.7428e-02, -2.1399e-01, -3.0110e-01,  2.2920e-01, -3.8049e-01,\n",
              "                                                         1.5834e-01,  2.5018e-01, -3.2356e-01, -4.5978e-02, -1.6657e-01,\n",
              "                                                         1.7146e-01,  9.9999e-01, -2.6098e-01, -1.6209e-01, -9.9999e-01,\n",
              "                                                        -4.6891e-01, -2.7055e-01,  2.7301e-01,  1.6969e-01, -3.1661e-01,\n",
              "                                                        -7.0246e-02,  1.8259e-01, -1.8207e-01, -2.7109e-01,  3.0935e-01,\n",
              "                                                         4.0538e-01, -2.0407e-01,  1.3230e-01,  1.6996e-01,  5.7928e-02,\n",
              "                                                         1.4196e-01, -9.9999e-01, -1.0303e-01,  2.0970e-02, -4.2683e-02,\n",
              "                                                        -1.0149e-01, -2.2298e-01, -2.2930e-01, -1.1753e-01,  1.3490e-01,\n",
              "                                                         2.1198e-01,  2.2512e-01, -1.0939e-01, -2.5720e-01, -3.8533e-01,\n",
              "                                                         1.8747e-01, -1.2891e-01,  6.6848e-02, -2.2334e-01, -2.9430e-01,\n",
              "                                                         6.9859e-02,  2.0419e-01,  4.1753e-02,  2.8188e-01, -1.8594e-01,\n",
              "                                                         2.6414e-01, -2.4761e-01,  9.9999e-01,  1.9128e-01, -2.0234e-01,\n",
              "                                                         9.9999e-01,  2.6540e-01, -6.9420e-02, -5.2516e-01,  1.1561e-01,\n",
              "                                                         1.1352e-01,  9.9999e-01,  1.2856e-01, -3.0153e-01, -1.6637e-01,\n",
              "                                                         1.0502e-01,  2.0734e-01,  4.9180e-01, -4.1181e-03, -9.9999e-01,\n",
              "                                                         1.0031e-01,  1.9071e-01, -5.1545e-02, -6.5302e-02,  9.9999e-01,\n",
              "                                                        -9.6873e-02, -1.9128e-01,  1.1409e-01,  3.3795e-01,  1.3597e-01,\n",
              "                                                         3.7522e-01,  2.6428e-01, -9.0982e-02, -2.0914e-01, -1.1833e-01,\n",
              "                                                        -1.1229e-01, -3.4681e-01, -2.2249e-01,  1.0144e-01, -1.6956e-01,\n",
              "                                                        -1.1350e-01, -2.2901e-01,  3.6746e-02, -4.0213e-02,  9.9999e-01,\n",
              "                                                        -1.5811e-02,  1.7973e-01,  7.8818e-02,  1.9868e-01,  9.2020e-02,\n",
              "                                                        -7.2586e-02, -6.5820e-02, -3.6706e-01,  3.4459e-01, -2.6499e-01,\n",
              "                                                         1.7574e-01,  1.1026e-01,  5.2395e-02, -2.4073e-01, -1.0504e-01,\n",
              "                                                        -2.4620e-01,  2.0411e-01,  3.9539e-02,  5.3742e-01,  2.3484e-01,\n",
              "                                                        -1.6248e-01, -1.3831e-01,  2.2213e-01, -5.6143e-02,  2.6474e-01,\n",
              "                                                        -1.8035e-01,  9.9999e-01,  2.3786e-01, -1.9461e-01, -4.1616e-02,\n",
              "                                                        -1.0487e-01, -2.5266e-01, -1.6942e-01, -2.8441e-01,  5.9210e-01,\n",
              "                                                         1.1692e-01,  8.8994e-02,  1.4863e-01,  2.7514e-01, -8.7180e-02,\n",
              "                                                        -1.1124e-01,  1.6170e-01,  6.5175e-02,  4.0325e-02, -3.3775e-01,\n",
              "                                                        -9.9999e-01, -3.0970e-01,  1.5965e-01, -4.2635e-01, -2.5099e-01,\n",
              "                                                         1.5365e-03, -3.2543e-01, -1.5290e-01, -1.8129e-02,  7.3798e-02,\n",
              "                                                         5.0980e-02, -2.6010e-01, -2.0882e-01,  1.4205e-01, -1.4203e-01,\n",
              "                                                        -2.4697e-01,  1.9888e-01,  3.1164e-01,  3.2071e-01, -8.3327e-02,\n",
              "                                                         2.7376e-01,  1.7164e-01, -1.4848e-02,  2.0021e-01, -1.1181e-01,\n",
              "                                                         8.8273e-02, -3.5306e-01, -3.8330e-01, -1.9634e-01, -2.2946e-01,\n",
              "                                                         2.1131e-01, -2.8591e-01, -7.3601e-02,  1.2059e-01, -1.9083e-01,\n",
              "                                                         2.5192e-01,  1.9797e-01, -9.7534e-02, -1.8096e-01,  7.1655e-02,\n",
              "                                                        -7.0444e-02,  1.2615e-01, -3.8281e-01,  2.4260e-01, -1.2130e-02,\n",
              "                                                         1.8283e-01, -1.9107e-01, -3.1621e-03,  1.8127e-01, -2.2065e-01,\n",
              "                                                         1.7145e-01,  1.6610e-01,  2.1985e-01, -1.2444e-01, -2.6440e-01,\n",
              "                                                         3.6380e-02,  7.6215e-02,  2.8593e-01,  9.0590e-02, -1.8787e-01,\n",
              "                                                        -1.8267e-01, -2.0696e-01, -2.7640e-01, -1.0037e-02,  2.3924e-02,\n",
              "                                                        -9.9999e-01, -2.6962e-02, -2.0045e-01, -2.2580e-01,  2.4630e-01,\n",
              "                                                         9.2688e-02,  3.3989e-01, -2.0107e-02, -5.6714e-01,  2.8104e-01,\n",
              "                                                        -1.4707e-01, -2.9393e-01,  3.2152e-02,  1.3769e-01, -4.8022e-02,\n",
              "                                                         8.6200e-02, -9.9999e-01,  6.7207e-02,  2.5256e-01, -2.3375e-01,\n",
              "                                                         1.9723e-01,  1.8645e-01, -1.2572e-01,  1.3193e-01, -1.1801e-01,\n",
              "                                                         9.1986e-01,  9.8561e-02,  1.1744e-01, -1.2444e-01, -4.9977e-03,\n",
              "                                                        -2.2342e-01, -2.9113e-01, -1.8557e-01,  1.6803e-01, -2.7972e-02,\n",
              "                                                         1.7035e-01, -2.5341e-01,  2.5812e-01,  8.0004e-02,  4.3675e-01,\n",
              "                                                         2.2243e-01, -1.0360e-01,  8.2666e-02, -1.5962e-01,  1.8148e-01,\n",
              "                                                         1.2144e-01,  3.1488e-01, -1.0175e-01, -1.0262e-02,  1.7214e-01,\n",
              "                                                        -1.6515e-01,  1.9851e-01,  1.6968e-01,  9.3980e-02,  3.4524e-01,\n",
              "                                                         2.1478e-01,  2.7286e-01, -1.2090e-01, -1.3934e-01,  1.6480e-01,\n",
              "                                                         1.2709e-01, -3.1015e-01,  7.5589e-02,  1.4997e-01, -3.8406e-02,\n",
              "                                                        -4.3522e-02,  1.2363e-01, -1.9284e-01,  1.3526e-01, -2.3024e-01,\n",
              "                                                        -2.3264e-01, -1.8424e-01,  1.6026e-01, -1.1861e-01, -3.2132e-01,\n",
              "                                                         2.4170e-01, -1.9905e-01, -2.7806e-01, -1.4937e-01, -7.5356e-03,\n",
              "                                                         2.1491e-01, -2.6794e-01, -1.5013e-01,  1.8138e-01,  3.0317e-01,\n",
              "                                                         5.7694e-02,  2.1159e-01,  1.6390e-01, -1.2928e-01,  4.6134e-02,\n",
              "                                                         2.1114e-01, -2.5208e-01, -3.5166e-01,  2.0573e-01,  1.5310e-01,\n",
              "                                                         8.7928e-02,  1.9220e-01,  6.6093e-02, -2.9686e-01,  2.3148e-01,\n",
              "                                                         8.0450e-02, -9.1040e-02, -2.0886e-01,  1.3427e-01, -1.5787e-01,\n",
              "                                                        -1.6571e-01,  1.9406e-01, -9.9999e-01, -3.6244e-03, -8.9661e-02,\n",
              "                                                        -1.3008e-01,  3.1503e-01,  2.6301e-01,  2.0833e-01,  2.2039e-01,\n",
              "                                                        -3.5182e-02, -2.4805e-01, -2.8496e-01, -3.5234e-02, -4.7605e-02,\n",
              "                                                        -5.6250e-01,  1.1065e-01,  3.8267e-02, -1.0335e-01,  2.0949e-01,\n",
              "                                                        -4.6776e-01, -2.4236e-01, -1.9264e-01, -7.9509e-02,  2.5640e-01,\n",
              "                                                         1.3585e-01,  1.1146e-01, -4.2631e-01, -1.3797e-01, -4.2020e-02,\n",
              "                                                        -3.3589e-01, -3.2083e-01,  2.8107e-01,  2.4660e-01,  2.7439e-01,\n",
              "                                                        -6.5341e-01,  2.4811e-01, -2.2557e-01, -1.0728e-01,  1.3671e-01,\n",
              "                                                         1.7659e-01,  5.3338e-02, -1.9266e-01,  3.2107e-01, -1.6023e-01,\n",
              "                                                        -2.1777e-01,  1.0947e-01, -3.1034e-01,  1.6971e-01, -8.8409e-01,\n",
              "                                                         2.5713e-01,  1.5591e-01,  3.4103e-01, -2.2164e-01,  2.5962e-01,\n",
              "                                                         1.5191e-01,  1.2868e-01,  6.3957e-02,  2.0855e-01,  2.8089e-02,\n",
              "                                                         3.6860e-01, -1.4804e-01,  2.7331e-01,  4.2737e-01, -9.9999e-01,\n",
              "                                                        -1.2161e-01, -1.1271e-01, -2.3094e-01, -9.9999e-01, -1.4309e-01,\n",
              "                                                         1.6571e-01,  8.9037e-02,  2.0814e-01, -3.1244e-02,  2.2422e-01,\n",
              "                                                         3.3944e-01, -2.1243e-01, -2.2818e-01,  2.4313e-01, -2.5976e-01,\n",
              "                                                        -3.0441e-02,  2.5024e-01, -2.2388e-01, -1.9171e-01,  1.5171e-01,\n",
              "                                                         3.2445e-01,  4.3148e-01, -3.2403e-02, -5.4172e-01,  4.6540e-01,\n",
              "                                                        -1.2867e-01, -1.2872e-01, -4.5294e-01, -1.9522e-01,  2.7236e-01,\n",
              "                                                        -2.0256e-05,  1.6263e-01,  1.8271e-01,  2.9891e-01, -9.6923e-02,\n",
              "                                                        -2.4060e-01,  5.9647e-02, -1.2879e-01,  3.1317e-01,  1.3269e-01,\n",
              "                                                         1.5556e-01, -5.0566e-02,  5.3613e-01, -2.8093e-01, -1.4543e-01,\n",
              "                                                         3.8241e-02, -2.9764e-02,  4.5187e-01, -1.4331e-01, -2.3235e-01,\n",
              "                                                         3.9609e-01, -2.5692e-01, -1.0771e-01,  2.4073e-01,  1.2628e-01,\n",
              "                                                        -2.6284e-01, -1.0109e-01, -1.2280e-01,  3.4987e-01, -9.9999e-01,\n",
              "                                                        -8.0383e-02, -1.3164e-01,  2.1572e-01,  1.7950e-02, -1.7570e-01,\n",
              "                                                         8.7421e-01,  4.5491e-01,  8.7202e-02,  2.9448e-01, -3.2925e-01,\n",
              "                                                        -1.3678e-01, -3.7717e-01,  1.4726e-01,  1.3700e-01, -5.8430e-02,\n",
              "                                                         2.6105e-02, -1.6864e-01, -1.6733e-01]], grad_fn=<TanhBackward0>))])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "hi_sent = \"सोच मशीन\"\n",
        "tokenizer_output = mbert_tokenizer(hi_sent, return_tensors=\"pt\")\n",
        "input_ids, attn_mask = tokenizer_output[\"input_ids\"], tokenizer_output[\"attention_mask\"]\n",
        "\n",
        "mbert_model(input_ids, attention_mask = attn_mask)"
      ],
      "id": "6b0d2bf6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5877901b"
      },
      "source": [
        "Hence, we can very easily use mBERT for generating predictions on texts written in different languages."
      ],
      "id": "5877901b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b6f23d0"
      },
      "source": [
        "## Task 1: Fine-tune mBERT on XNLI\n",
        "\n",
        "We can now start fine-tuning mBERT on this dataset. We will start by defining the custom `Dataset` class for the task and then define the model and training loop."
      ],
      "id": "6b6f23d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45bf6240"
      },
      "source": [
        "## Task 1.1: Custom Dataset Class (2 Marks)\n",
        "\n",
        "Like in the previous assignments, implement the `XNLImBertDataset` class below that processes and stores the data as well as provides a way to iterate through the dataset. The details about various methods in the class are mentioned in their docstrings"
      ],
      "id": "45bf6240"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "984d8f79"
      },
      "outputs": [],
      "source": [
        "class XNLImBertDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, premises,\n",
        "                 hypotheses,\n",
        "                 labels,\n",
        "                 max_length,\n",
        "                mbert_variant = \"bert-base-multilingual-uncased\"):\n",
        "        \n",
        "        \"\"\"\n",
        "        Constructor for the `XNLImBertDataset` class. Stores the `premises`, `hypotheses` and `labels`\n",
        "        which can then be used by other methods. Also initializes the tokenizer.\n",
        "        \n",
        "        Inputs:\n",
        "            - premises (list) : A list of sentences constituting the premise in each example\n",
        "            - hypotheses (list) : A list of sentences constituting the hypothesis in each example\n",
        "            - labels (list) : A list of labels denoting for each premise-hypothesis pair.\n",
        "            - max_length (int): Maximum length of the encoded sequence.  \n",
        "                                If number of tokens are lower than `max_length` add padding otherwise truncate\n",
        "        \n",
        "        \n",
        "        Note that labels are in the form of strings \"entailment\", \"contradiction\" and \"neutral\". For training the\n",
        "        models we will want the labels in the numeric form, so you should define a mapping from the text label\n",
        "        to a numeric id. You should order the labels in alphabetical order while defining the mapping i.e. \n",
        "        contadiction -> 0, entailment -> 1, \"neutral\" - > 2 (such that we have consistency across everyone) \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        self.premises = premises\n",
        "        self.hypotheses = hypotheses\n",
        "        self.labels = labels\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(mbert_variant)\n",
        "        self.label2id = {'contradiction':0, 'entailment':1, 'neutral' : 2}\n",
        "        \n",
        "        # self. labels = [self.label2id[label] for label in self.labels]\n",
        "        \n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the length of the dataset\n",
        "        \"\"\"\n",
        "        length = len(self.premises)\n",
        "        \n",
        "        return length\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        \n",
        "        Returns the features and label corresponding to the the `idx` entry in the dataset.\n",
        "        \n",
        "        Inputs:\n",
        "            - idx (int): Index corresponding to the sentence_pair,label to be returned\n",
        "        \n",
        "        Returns:\n",
        "            - input_ids (torch.tensor): Indices of the tokens in the sentence pair.\n",
        "                                        Shape of the tensor should be (`seq_len`,)\n",
        "            - mask (torch.tensor): Attention mask indicating which tokens are padded.\n",
        "            - label (int): Label for the premise-hypothesis pair\n",
        "            \n",
        "        Hint: We have 2 sentences in a pair which must be concatenated using the [SEP] token before we tokenize and encode them\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        \n",
        "        tokenized =  self.tokenizer (self.premises[idx]+\"[SEP]\"+self.hypotheses[idx],max_length = self.max_length, padding = 'max_length', truncation = True, return_tensors = 'pt')\n",
        "        input_ids = tokenized['input_ids']\n",
        "        mask = tokenized['attention_mask']\n",
        "        label = self.label2id[self.labels[idx]]\n",
        "        \n",
        "        return input_ids.squeeze(0), mask.squeeze(0), label"
      ],
      "id": "984d8f79"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4e1ba52b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064ca694-47ba-4ca7-a443-affca8ebddef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1: Checking if `__len__` is implemented correctly\n",
            "Dataset Length: 3\n",
            "Expected Length: 3\n",
            "Sample Test Case Passed!\n",
            "****************************************\n",
            "\n",
            "Sample Test Case 2: Checking if `__getitem__` is implemented correctly for `idx= 0`\n",
            "input_ids:\n",
            " tensor([  101,   143, 10564, 15450, 84789, 10107, 10103, 38884, 10108,   143,\n",
            "        16745, 10104, 10970, 11344, 17147, 11913,   119,   102, 10103, 10564,\n",
            "        10127, 55860,   119,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "Expected input_ids:\n",
            " tensor([  101,   143, 10564, 15450, 84789, 10107, 10103, 38884, 10108,   143,\n",
            "        16745, 10104, 10970, 11344, 17147, 11913,   119,   102, 10103, 10564,\n",
            "        10127, 55860,   119,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "mask:\n",
            " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Expected mask:\n",
            " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "label:\n",
            " 0\n",
            "Expected label:\n",
            " 0\n",
            "Sample Test Case Passed!\n",
            "****************************************\n",
            "\n",
            "Sample Test Case 3: Checking if `__getitem__` is implemented correctly for `idx= 1`\n",
            "input_ids:\n",
            " tensor([  101, 10144, 18585, 10110, 24392, 10564, 14965, 64581,   119,   102,\n",
            "        10536, 10562, 10320, 14965, 64581, 10110, 18418, 82863, 10160, 10103,\n",
            "        45670, 14734, 10125, 10103, 21005,   119,   102,     0,     0,     0,\n",
            "            0,     0])\n",
            "Expected input_ids:\n",
            " tensor([  101, 10144, 18585, 10110, 24392, 10564, 14965, 64581,   119,   102,\n",
            "        10536, 10562, 10320, 14965, 64581, 10110, 18418, 82863, 10160, 10103,\n",
            "        45670, 14734, 10125, 10103, 21005,   119,   102,     0,     0,     0,\n",
            "            0,     0])\n",
            "mask:\n",
            " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0])\n",
            "Expected mask:\n",
            " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0])\n",
            "label:\n",
            " 2\n",
            "Expected label:\n",
            " 2\n",
            "Sample Test Case Passed!\n",
            "****************************************\n",
            "\n",
            "Sample Test Case 4: Checking if `__getitem__` is implemented correctly for `idx= 2`\n",
            "input_ids:\n",
            " tensor([  101,   143, 20071, 11336, 10171, 18248, 19592, 14734,   119,   102,\n",
            "        10970, 10562, 10320, 14734,   143, 13148,   119,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "Expected input_ids:\n",
            " tensor([  101,   143, 20071, 11336, 10171, 18248, 19592, 14734,   119,   102,\n",
            "        10970, 10562, 10320, 14734,   143, 13148,   119,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "mask:\n",
            " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Expected mask:\n",
            " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "label:\n",
            " 1\n",
            "Expected label:\n",
            " 1\n",
            "Sample Test Case Passed!\n",
            "****************************************\n",
            "\n",
            "Sample Test Case 5: Checking for hindi\n",
            "input_ids:\n",
            " tensor([  101, 11384,   569, 30119, 10949, 11142, 74535, 10949,   533, 13764,\n",
            "        25695,   571, 12114, 19086, 10949, 36335,   580,   591,   102,   568,\n",
            "        11551, 17109, 12334, 56426, 52061,   569, 28393, 41790, 20106, 11483,\n",
            "        91329, 19086, 29931,   533, 13764,   102])\n",
            "Expected input_ids:\n",
            " tensor([  101, 11384,   569, 30119, 10949, 11142, 74535, 10949,   533, 13764,\n",
            "        25695,   571, 12114, 19086, 10949, 36335,   580,   591,   102,   568,\n",
            "        11551, 17109, 12334, 56426, 52061,   569, 28393, 41790, 20106, 11483,\n",
            "        91329, 19086, 29931,   533, 13764,   102])\n",
            "mask:\n",
            " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Expected mask:\n",
            " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "label:\n",
            " 2\n",
            "Expected label:\n",
            " 2\n",
            "Sample Test Case Passed!\n",
            "****************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "sample_premises = [\"A man inspects the uniform of a figure in some East Asian country.\",\n",
        "                    \"An older and younger man smiling.\",\n",
        "                   \"A soccer game with multiple males playing.\"\n",
        "                    ]\n",
        "sample_hypotheses = [\"The man is sleeping.\",\n",
        "                     \"Two men are smiling and laughing at the cats playing on the floor.\",\n",
        "                    \"Some men are playing a sport.\"]\n",
        "sample_labels = [\"contradiction\", \"neutral\", \"entailment\"]\n",
        "sample_max_len = 32\n",
        "sample_dataset = XNLImBertDataset(\n",
        "    sample_premises,\n",
        "    sample_hypotheses,\n",
        "    sample_labels,\n",
        "    sample_max_len\n",
        ")\n",
        "print(f\"Sample Test Case 1: Checking if `__len__` is implemented correctly\")\n",
        "dataset_len= len(sample_dataset)\n",
        "expected_len = len(sample_labels)\n",
        "print(f\"Dataset Length: {dataset_len}\")\n",
        "print(f\"Expected Length: {expected_len}\")\n",
        "assert len(sample_dataset) == len(sample_premises)\n",
        "print(\"Sample Test Case Passed!\")\n",
        "print(\"****************************************\\n\")\n",
        "\n",
        "print(f\"Sample Test Case 2: Checking if `__getitem__` is implemented correctly for `idx= 0`\")\n",
        "sample_idx = 0\n",
        "input_ids, mask, label = sample_dataset.__getitem__(sample_idx)\n",
        "expected_input_ids =  torch.tensor([  101,   143, 10564, 15450, 84789, 10107, 10103, 38884, 10108,   143,\n",
        "        16745, 10104, 10970, 11344, 17147, 11913,   119,   102, 10103, 10564,\n",
        "        10127, 55860,   119,   102,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0])\n",
        "expected_mask = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0])\n",
        "expected_label = 0\n",
        "print(f\"input_ids:\\n {input_ids}\")\n",
        "print(f\"Expected input_ids:\\n {expected_input_ids}\")\n",
        "assert (expected_input_ids == input_ids).all()\n",
        "\n",
        "print(f\"mask:\\n {mask}\")\n",
        "print(f\"Expected mask:\\n {expected_mask}\")\n",
        "assert (expected_mask == mask).all()\n",
        "\n",
        "print(f\"label:\\n {label}\")\n",
        "print(f\"Expected label:\\n {expected_label}\")\n",
        "assert expected_label == label\n",
        "\n",
        "print(\"Sample Test Case Passed!\")\n",
        "print(\"****************************************\\n\")\n",
        "\n",
        "print(f\"Sample Test Case 3: Checking if `__getitem__` is implemented correctly for `idx= 1`\")\n",
        "sample_idx = 1\n",
        "input_ids, mask, label = sample_dataset.__getitem__(sample_idx)\n",
        "expected_input_ids = torch.tensor([  101, 10144, 18585, 10110, 24392, 10564, 14965, 64581,   119,   102,\n",
        "        10536, 10562, 10320, 14965, 64581, 10110, 18418, 82863, 10160, 10103,\n",
        "        45670, 14734, 10125, 10103, 21005,   119,   102,     0,     0,     0,\n",
        "            0,     0])\n",
        "expected_mask = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 0, 0, 0, 0, 0])\n",
        "expected_label = 2\n",
        "print(f\"input_ids:\\n {input_ids}\")\n",
        "print(f\"Expected input_ids:\\n {expected_input_ids}\")\n",
        "assert (expected_input_ids == input_ids).all()\n",
        "\n",
        "print(f\"mask:\\n {mask}\")\n",
        "print(f\"Expected mask:\\n {expected_mask}\")\n",
        "assert (expected_mask == mask).all()\n",
        "\n",
        "print(f\"label:\\n {label}\")\n",
        "print(f\"Expected label:\\n {expected_label}\")\n",
        "assert expected_label == label\n",
        "\n",
        "print(\"Sample Test Case Passed!\")\n",
        "print(\"****************************************\\n\")\n",
        "\n",
        "\n",
        "print(f\"Sample Test Case 4: Checking if `__getitem__` is implemented correctly for `idx= 2`\")\n",
        "sample_idx = 2\n",
        "input_ids, mask, label = sample_dataset.__getitem__(sample_idx)\n",
        "expected_input_ids = torch.tensor([  101,   143, 20071, 11336, 10171, 18248, 19592, 14734,   119,   102,\n",
        "        10970, 10562, 10320, 14734,   143, 13148,   119,   102,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0])\n",
        "expected_mask = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0])\n",
        "expected_label = 1\n",
        "print(f\"input_ids:\\n {input_ids}\")\n",
        "print(f\"Expected input_ids:\\n {expected_input_ids}\")\n",
        "assert (expected_input_ids == input_ids).all()\n",
        "\n",
        "print(f\"mask:\\n {mask}\")\n",
        "print(f\"Expected mask:\\n {expected_mask}\")\n",
        "assert (expected_mask == mask).all()\n",
        "\n",
        "print(f\"label:\\n {label}\")\n",
        "print(f\"Expected label:\\n {expected_label}\")\n",
        "assert expected_label == label\n",
        "\n",
        "print(\"Sample Test Case Passed!\")\n",
        "print(\"****************************************\\n\")\n",
        "\n",
        "\n",
        "\n",
        "sample_premises = [\"एक आदमी किसी पूर्वी एशियाई देश में एक आकृति की वर्दी का निरीक्षण करता है।\",\n",
        "                    \"एक बूढ़ा और छोटा आदमी मुस्कुरा रहा है।\",\n",
        "                   \"एक फ़ुटबॉल खेल जिसमें कई पुरुष खेल रहे हैं।\"\n",
        "                    ]\n",
        "sample_sentence2s = [\"आदमी सो रहा है।\",\n",
        "                     \"फर्श पर खेल रही बिल्लियों को देखकर दो आदमी मुस्कुरा रहे हैं और हंस रहे हैं।\",\n",
        "                    \"कुछ पुरुष कोई खेल खेल रहे हैं।\"\n",
        "                    ]\n",
        "sample_labels = [\"contradiction\", \"neutral\", \"entailment\"]\n",
        "sample_max_len = 36\n",
        "sample_dataset = XNLImBertDataset(\n",
        "    sample_premises,\n",
        "    sample_sentence2s,\n",
        "    sample_labels,\n",
        "    sample_max_len\n",
        ")\n",
        "\n",
        "print(f\"Sample Test Case 5: Checking for hindi\")\n",
        "sample_idx = 1\n",
        "input_ids, mask, label = sample_dataset.__getitem__(sample_idx)\n",
        "expected_input_ids =  torch.tensor([  101, 11384,   569, 30119, 10949, 11142, 74535, 10949,   533, 13764,\n",
        "        25695,   571, 12114, 19086, 10949, 36335,   580,   591,   102,   568,\n",
        "        11551, 17109, 12334, 56426, 52061,   569, 28393, 41790, 20106, 11483,\n",
        "        91329, 19086, 29931,   533, 13764,   102])\n",
        "expected_mask = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
        "expected_label = 2\n",
        "print(f\"input_ids:\\n {input_ids}\")\n",
        "print(f\"Expected input_ids:\\n {expected_input_ids}\")\n",
        "assert (expected_input_ids == input_ids).all()\n",
        "\n",
        "print(f\"mask:\\n {mask}\")\n",
        "print(f\"Expected mask:\\n {expected_mask}\")\n",
        "assert (expected_mask == mask).all()\n",
        "\n",
        "print(f\"label:\\n {label}\")\n",
        "print(f\"Expected label:\\n {expected_label}\")\n",
        "assert expected_label == label\n",
        "\n",
        "print(\"Sample Test Case Passed!\")\n",
        "print(\"****************************************\\n\")\n",
        "\n",
        "\n"
      ],
      "id": "4e1ba52b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3863fe4d"
      },
      "source": [
        "Initialize dataset and dataloaders for english training and validation sets"
      ],
      "id": "3863fe4d"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "80913533"
      },
      "outputs": [],
      "source": [
        "max_seq_len = 128\n",
        "batch_size = 8\n",
        "\n",
        "train_en_premises, train_en_hypotheses = train_en_data[\"premise\"].values, train_en_data[\"hypothesis\"].values\n",
        "train_en_labels = train_en_data[\"label\"].values\n",
        "\n",
        "val_en_premises, val_en_hypotheses = val_en_data[\"premise\"].values, val_en_data[\"hypothesis\"].values\n",
        "val_en_labels = val_en_data[\"label\"].values\n",
        "\n",
        "train_en_dataset = XNLImBertDataset(train_en_premises, train_en_hypotheses, train_en_labels, max_seq_len)\n",
        "val_en_dataset = XNLImBertDataset(val_en_premises, val_en_hypotheses, val_en_labels, max_seq_len)\n",
        "\n",
        "train_en_dataloader = DataLoader(train_en_dataset, batch_size = batch_size)\n",
        "val_en_dataloader = DataLoader(val_en_dataset, batch_size = batch_size)"
      ],
      "id": "80913533"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ca63c08"
      },
      "source": [
        "## Task 1.2: Implement mBERT Based Classifier for NLI (2 Marks)\n",
        "\n",
        "Similar to last assignment implement a classifier with an mBERT module followed by a classification layer. Note that unlike last time we have 3 classes now, so we can no longer use Sigmoid function in the output layer and instead will need to use the Softmax function. You can refer [here](https://cs231n.github.io/linear-classify/#softmax-classifier) if you need a primer on how the softmax function works. Hence, this time instead of getting a single output from the model for an input, denoting the probability of the poistive class, we will get 3 numbers as output for each input denoting the probability of each of the 3 classes. Also, it is common to use Log of the Softmax function instead of plain softmax to obtain log-probabilities. Log-Softmax is numerically more stable and hence it is often more used in practice. You can read about it's usage in pytorch [here](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html). Implement the `mBERTNLIClassifierModel` below"
      ],
      "id": "5ca63c08"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "874c8194"
      },
      "outputs": [],
      "source": [
        "\n",
        "class mBERTNLIClassifierModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_hidden = 768, mbert_variant = \"bert-base-multilingual-uncased\"):\n",
        "        \n",
        "        \"\"\"\n",
        "        Constructor for the `mBERTNLIClassifierModel` class. Use this to define  the network architecture\n",
        "        which should be: Input -> mBERT -> Linear Layer -> Log-Softmax\n",
        "        \n",
        "        Inputs:\n",
        "            - d_hidden (int): Size of the hidden representations of mbert\n",
        "            - mbert_variant (str): mBERT variant to use\n",
        "        \n",
        "        \"\"\"\n",
        "        super(mBERTNLIClassifierModel, self).__init__()\n",
        "        \n",
        "        self.mbert_layer = BertModel.from_pretrained(mbert_variant)\n",
        "        self.output_layer = nn.Linear(d_hidden,3)\n",
        "        self.log_softmax_layer = nn.LogSoftmax()\n",
        "        \n",
        "\n",
        "    def forward(self, input_ids, attn_mask):\n",
        "        \n",
        "        \"\"\"\n",
        "        Forward Passes the inputs through the network and obtains the prediction\n",
        "        \n",
        "        Inputs:\n",
        "            - input_ids (torch.tensor): A torch tensor of shape [batch_size, seq_len]\n",
        "                                        representing the sequence of token ids\n",
        "            - attn_mask (torch.tensor): A torch tensor of shape [batch_size, seq_len]\n",
        "                                        representing the attention mask such that padded tokens are 0 and rest 1\n",
        "                                        \n",
        "        Returns:\n",
        "          - output (torch.tensor): A torch tensor of shape [batch_size, 3] containing (log) probabilities\n",
        "          of each class \n",
        "                                                \n",
        "        \"\"\"\n",
        "        for idx in range(len(input_ids)):\n",
        "          \n",
        "          _, output = self.mbert_layer(input_ids, attention_mask = attn_mask, return_dict = False)\n",
        "          output = self.output_layer(output)\n",
        "          output = self.log_softmax_layer(output)\n",
        "        return output"
      ],
      "id": "874c8194"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "06229181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83816649-c11e-4275-bec7-5f001ee78784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Test Case 1\n",
            "Model Output: [[-0.9885042 -1.479876  -0.9157878]]\n",
            "Expected Output: [[-0.9885041 -1.479876  -0.915788 ]]\n",
            "Test Case Passed! :)\n",
            "******************************\n",
            "\n",
            "Sample Test Case 2\n",
            "Model Output: [[-0.97441864 -1.477538   -0.9304163 ]]\n",
            "Expected Output: [[-0.97441876 -1.4775381  -0.9304163 ]]\n",
            "Test Case Passed! :)\n",
            "******************************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Running Sample Test Cases!\")\n",
        "torch.manual_seed(42)\n",
        "model = mBERTNLIClassifierModel()\n",
        "\n",
        "sample_premises = [\"A man inspects the uniform of a figure in some East Asian country.\",\n",
        "                    \"An older and younger man smiling.\",\n",
        "                   \"A soccer game with multiple males playing.\"\n",
        "                    ]\n",
        "sample_hypotheses = [\"The man is sleeping.\",\n",
        "                     \"Two men are smiling and laughing at the cats playing on the floor.\",\n",
        "                    \"Some men are playing a sport.\"]\n",
        "sample_labels = [\"contradiction\", \"neutral\", \"entailment\"]\n",
        "sample_max_len = 32\n",
        "sample_dataset = XNLImBertDataset(\n",
        "    sample_premises,\n",
        "    sample_hypotheses,\n",
        "    sample_labels,\n",
        "    sample_max_len\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Sample Test Case 1\")\n",
        "sample_idx = 0\n",
        "input_ids, attn_mask, label = sample_dataset.__getitem__(sample_idx)\n",
        "mbert_cls_out = model(input_ids.unsqueeze(0), attn_mask.unsqueeze(0)).detach().numpy()\n",
        "expected_mbert_cls_out = np.array([[-0.9885041, -1.479876,  -0.915788 ]])\n",
        "print(f\"Model Output: {mbert_cls_out }\")\n",
        "print(f\"Expected Output: {expected_mbert_cls_out}\")\n",
        "\n",
        "assert mbert_cls_out .shape == expected_mbert_cls_out.shape\n",
        "assert np.allclose(mbert_cls_out, expected_mbert_cls_out, 1e-4)\n",
        "print(\"Test Case Passed! :)\")\n",
        "print(\"******************************\\n\")\n",
        "\n",
        "print(\"Sample Test Case 2\")\n",
        "sample_idx = 1\n",
        "input_ids, attn_mask, label = sample_dataset.__getitem__(sample_idx)\n",
        "mbert_cls_out = model(input_ids.unsqueeze(0), attn_mask.unsqueeze(0)).detach().numpy()\n",
        "expected_mbert_cls_out = np.array([[-0.97441876, -1.4775381,  -0.9304163 ]])\n",
        "print(f\"Model Output: {mbert_cls_out }\")\n",
        "print(f\"Expected Output: {expected_mbert_cls_out}\")\n",
        "\n",
        "assert mbert_cls_out .shape == expected_mbert_cls_out.shape\n",
        "assert np.allclose(mbert_cls_out, expected_mbert_cls_out, 1e-4)\n",
        "print(\"Test Case Passed! :)\")\n",
        "print(\"******************************\\n\")\n"
      ],
      "id": "06229181"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30c8ca8f"
      },
      "source": [
        "## Task 1.3: Training and Evaluating the Model (4 Marks)\n",
        "\n",
        "Similar to previous assignments implement the `train` and `evaluate` functions below. There will be though a couple of differences this time. First, for training the model we can no longer use Binary Cross Entropy Loss because as the name suggests it is applicable for binary classification problems. Instead we will use the [Negative Log-Likelihood Loss function](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html) instead. Second, while evaluating the accuracy we can no longer use a threshold to convert the probabilities into the labels, since we will now have 3 probability values instead of a single one, corresponding to the each class. In such cases it is common to predict the class as the label which has the highest probability (or equivalently log probability).\n"
      ],
      "id": "30c8ca8f"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "787c97cf"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_dataloader, device = \"cuda\"):\n",
        "    \n",
        "    \"\"\"\n",
        "    Evaluates `model` on test dataset\n",
        "\n",
        "    Inputs:\n",
        "        - model (mBERTNLIClassifierModel): mBERT based classifier model to be evaluated\n",
        "        - test_dataloader (torch.utils.DataLoader): A dataloader defined over the test dataset\n",
        "\n",
        "    Returns:\n",
        "        - accuracy (float): Average accuracy over the test dataset \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    accuracy = 0\n",
        "    \n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for test_batch in test_dataloader:\n",
        "        features, masks, labels = test_batch\n",
        "\n",
        "        features = features.to(device).long()\n",
        "        masks = masks.to(device).long()\n",
        "        labels = labels.to(device).long()\n",
        "\n",
        "        # Probability predictions from the model\n",
        "        pred_probs = model(features,masks).to(device)\n",
        "\n",
        "        # Convert predictions and labels to numpy arrays from torch tensors \n",
        "        predictions = np.argmax( pred_probs.detach().cpu().numpy(), axis = 1).tolist()\n",
        "        labels = labels.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "        batch_accuracy = None\n",
        "        correct_predictions=0\n",
        "        # print(predictions, labels)\n",
        "        for prediction,actual in zip(predictions,labels):\n",
        "          if prediction==actual:\n",
        "            correct_predictions+=1\n",
        "        batch_accuracy=correct_predictions/len(predictions)\n",
        "\n",
        "\n",
        "        accuracy += batch_accuracy\n",
        "\n",
        "      # Divide by number of batches to get average accuracy\n",
        "      accuracy = accuracy / len(test_dataloader)\n",
        "\n",
        "\n",
        "    \n",
        "    return accuracy\n",
        "    \n",
        "    \n",
        "    \n",
        "def train(model, train_dataloader, val_dataloader,\n",
        "          lr = 1e-5, num_epochs = 3,\n",
        "          device = \"cpu\"):\n",
        "    \n",
        "    \"\"\"\n",
        "    Runs the training loop. Define the loss function as NLLLoss\n",
        "    and optimizer as Adam and train for `num_epochs` epochs.\n",
        "\n",
        "    Inputs:\n",
        "        - model (mBERTNLIClassifierModel): mBERT based classifer model to be trained\n",
        "        - train_dataloader (torch.utils.DataLoader): A dataloader defined over the training dataset\n",
        "        - val_dataloader (torch.utils.DataLoader): A dataloader defined over the validation dataset\n",
        "        - lr (float): The learning rate for the optimizer\n",
        "        - num_epochs (int): Number of epochs to train the model for.\n",
        "        - device (str): Device to train the model on. Can be either 'cuda' (for using gpu) or 'cpu'\n",
        "\n",
        "    Returns:\n",
        "        - best_model (mBERTNLIClassifierModel): model corresponding to the highest validation accuracy (checked at the end of each epoch)\n",
        "        - best_val_accuracy (float): Validation accuracy corresponding to the best epoch\n",
        "    \"\"\"\n",
        "        \n",
        "    best_val_accuracy = float(\"-inf\")\n",
        "    best_model = None\n",
        "    model = model.to(device)\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    loss_fn = nn.NLLLoss()\n",
        "    optimizer = Adam(model.parameters(),lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train() \n",
        "        epoch_loss = 0\n",
        "        for train_batch in tqdm.tqdm(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            features, masks, labels = train_batch\n",
        "\n",
        "            features = features.float()\n",
        "            labels = labels.to(torch.int64)\n",
        "\n",
        "            features  = torch.tensor(features)\n",
        "            masks = torch.tensor(masks)\n",
        "            \n",
        "            features = features.to(device).long()\n",
        "            masks = masks.to(device).float()\n",
        "            labels = labels.to(device)\n",
        "\n",
        "\n",
        "            preds = model(features, masks)\n",
        "            loss = loss_fn(preds,labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        \n",
        "        epoch_loss = epoch_loss / len(train_dataloader)\n",
        "        \n",
        "        print('Evaluating')\n",
        "        val_accuracy = evaluate(model,val_dataloader)\n",
        " \n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            best_model = copy.deepcopy(model) \n",
        "        \n",
        "        print(f\"Epoch {epoch} completed | Average Training Loss: {epoch_loss} | Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "        best_model.zero_grad()\n",
        "    return best_model, best_val_accuracy"
      ],
      "id": "787c97cf"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5c77e27c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0d4542-2b27-4092-cd7a-518927368792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 100 data points for sanity check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 13/13 [00:04<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 0 completed | Average Training Loss: 1.1242104401955237 | Validation Accuracy: 0.3557692307692308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:04<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 1 completed | Average Training Loss: 1.0847587218651404 | Validation Accuracy: 0.5576923076923077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:04<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 2 completed | Average Training Loss: 1.0078262870128338 | Validation Accuracy: 0.6730769230769231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:04<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 3 completed | Average Training Loss: 0.9527593484291663 | Validation Accuracy: 0.7115384615384616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:04<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 4 completed | Average Training Loss: 0.7570186532460726 | Validation Accuracy: 0.6346153846153846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:04<00:00,  2.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 5 completed | Average Training Loss: 0.7018076869157645 | Validation Accuracy: 0.6346153846153846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:04<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 6 completed | Average Training Loss: 0.7862338102780856 | Validation Accuracy: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:04<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 7 completed | Average Training Loss: 0.600664672943262 | Validation Accuracy: 0.9711538461538461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:04<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 8 completed | Average Training Loss: 0.3131307191573657 | Validation Accuracy: 0.9230769230769231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:04<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 9 completed | Average Training Loss: 0.1509376414693319 | Validation Accuracy: 1.0\n",
            "Best Validation Accuracy: 1.0\n",
            "Expected Best Validation Accuracy: 0.99\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "print(\"Training on 100 data points for sanity check\")\n",
        "\n",
        "max_seq_len = 128\n",
        "batch_size = 8\n",
        "\n",
        "sample_premises, sample_hypotheses = train_en_data[\"premise\"].values[:100], train_en_data[\"hypothesis\"].values[:100]\n",
        "sample_labels = train_en_data[\"label\"].values[:100]\n",
        "\n",
        "sample_dataset = XNLImBertDataset(sample_premises, sample_hypotheses, sample_labels, max_seq_len)\n",
        "sample_dataloader = DataLoader(sample_dataset, batch_size = batch_size)\n",
        "\n",
        "\n",
        "model = mBERTNLIClassifierModel()\n",
        "best_model, best_val_acc = train(model, sample_dataloader, sample_dataloader, lr = 5e-5, num_epochs = 10, device = \"cuda\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc}\")\n",
        "print(f\"Expected Best Validation Accuracy: {0.99}\")"
      ],
      "id": "5c77e27c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a628b8d9"
      },
      "source": [
        "Since we just trained and evaluated on same 100 examples, you should expect nearly perfect 99% accuracy. Now let's train on the entire dataset."
      ],
      "id": "a628b8d9"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "a8d168c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e9d113-58d0-4498-e3ba-ff552bc92ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  0%|          | 0/4750 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 4750/4750 [30:48<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 0 completed | Average Training Loss: 0.7769625133307356 | Validation Accuracy: 0.7145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4750/4750 [30:45<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            "Epoch 1 completed | Average Training Loss: 0.5599559139703449 | Validation Accuracy: 0.7355\n",
            "Best Validation Accuracy: 0.7355\n",
            "Expected Best Validation Accuracy: 0.7675\n"
          ]
        }
      ],
      "source": [
        "model = mBERTNLIClassifierModel()\n",
        "best_model, best_val_acc = train(model, train_en_dataloader, val_en_dataloader, lr = 1e-5, num_epochs = 2, device = \"cuda\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc}\")\n",
        "print(f\"Expected Best Validation Accuracy: {0.7675}\")"
      ],
      "id": "a8d168c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e700e982"
      },
      "source": [
        "## Task 1.4: Zero-Shot Transfer (2 Marks)\n",
        "\n",
        "Pre-trained multilingual models like mBERT have shown to exhibit zero-shot transfer capabilities to new langauges for which the model was never fine-tuned on. You can read more about zero-shot transfer in mBERT in this [paper](https://arxiv.org/abs/1906.01502). We now test this phenomenon for ourselves, where we will evaluate the performance of the mBERT classifier that we just trained on the English on the test sets in 15 different languages. Implement the `evaluate_on_diff_langs` function below that does that"
      ],
      "id": "e700e982"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7dcad1a6"
      },
      "outputs": [],
      "source": [
        "def evaluate_on_diff_langs(model, lang2test_df, max_length = 128, batch_size = 8, device = \"cpu\"):\n",
        "    \n",
        "    \"\"\"\n",
        "    Evaluates the accuracy of the fine-tuned model on test data in different langauges.\n",
        "    \n",
        "    Inputs:\n",
        "        - model (mBERTNLIClassifierModel): mBERT based classifer model fine-tuned on English data\n",
        "        - lang2test_df (dict): A dictionary with langauges as keys and\n",
        "                                their corresponding test sets (in form of pandas dataframe)\n",
        "                                as values\n",
        "                                \n",
        "    Returns:\n",
        "        - lang2acc (dict): A dictionary with language ids as keys and the accuracy on it's test set as values\n",
        "                            eg: {\"en\" : 0.8, \"fr\" : 0.77, \"hi\": 0.72, ...}\n",
        "    \n",
        "    \"\"\"\n",
        "    from tqdm import tqdm\n",
        "    lang2acc = {}\n",
        "\n",
        "\n",
        "    for lang, test_df in tqdm(lang2test_df.items()):\n",
        "      \n",
        "      sample_premises, sample_hypotheses = test_df[\"premise\"].values[:100], test_df[\"hypothesis\"].values[:100]\n",
        "      sample_labels = test_df[\"label\"].values[:100]\n",
        "\n",
        "      sample_dataset = XNLImBertDataset(sample_premises, sample_hypotheses, sample_labels, max_seq_len)\n",
        "      sample_dataloader = DataLoader(sample_dataset, batch_size = batch_size)\n",
        "\n",
        "\n",
        "      accuracy = evaluate(model,sample_dataloader,device=device)\n",
        "      lang2acc[lang]= accuracy\n",
        "\n",
        "    return lang2acc\n",
        "    "
      ],
      "id": "7dcad1a6"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "39ff6b5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406754cb-bc8f-445d-dde2-52af0b9d5ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 15/15 [01:14<00:00,  4.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langauge to Accuracy:\n",
            " {'ar': 0.6442307692307693, 'bg': 0.7019230769230769, 'de': 0.7211538461538461, 'el': 0.7403846153846154, 'en': 0.8269230769230769, 'es': 0.75, 'fr': 0.7884615384615384, 'hi': 0.5961538461538461, 'ru': 0.6826923076923077, 'sw': 0.5673076923076923, 'th': 0.3076923076923077, 'tr': 0.6730769230769231, 'ur': 0.6057692307692307, 'vi': 0.6538461538461539, 'zh': 0.6538461538461539}\n",
            "Expected Values:\n",
            " {'ar': 0.5989583333333334, 'bg': 0.6454326923076923, 'de': 0.6698717948717948, 'el': 0.6402243589743589, 'en': 0.7263621794871795, 'es': 0.6923076923076923, 'fr': 0.6802884615384616, 'hi': 0.5893429487179487, 'ru': 0.6478365384615384, 'sw': 0.53125, 'th': 0.35136217948717946, 'tr': 0.610176282051282, 'ur': 0.5637019230769231, 'vi': 0.6193910256410257, 'zh': 0.6073717948717948}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "lang2acc = evaluate_on_diff_langs(best_model, lang2test_df, max_length = 128, batch_size = 8, device = \"cuda\")\n",
        "expected_vals = {'ar': 0.5989583333333334,\n",
        " 'bg': 0.6454326923076923,\n",
        " 'de': 0.6698717948717948,\n",
        " 'el': 0.6402243589743589,\n",
        " 'en': 0.7263621794871795,\n",
        " 'es': 0.6923076923076923,\n",
        " 'fr': 0.6802884615384616,\n",
        " 'hi': 0.5893429487179487,\n",
        " 'ru': 0.6478365384615384,\n",
        " 'sw': 0.53125,\n",
        " 'th': 0.35136217948717946,\n",
        " 'tr': 0.610176282051282,\n",
        " 'ur': 0.5637019230769231,\n",
        " 'vi': 0.6193910256410257,\n",
        " 'zh': 0.6073717948717948}\n",
        "print(f\"Langauge to Accuracy:\\n {lang2acc}\")\n",
        "print(f\"Expected Values:\\n {expected_vals}\")"
      ],
      "id": "39ff6b5f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65558d2f"
      },
      "source": [
        "Don't worry if the values do not match exactly, but you can expect similar patterns i.e. the fine-tuned model on English data, performs reasonably on other new langauges as well compared to it's performance on English test data. Performance on langauges like German, French and Spanish is much closer to the performance on English. However, it is on the lower side for languages like Swahilli, Urdu and Thai. The values are still surprisingly high, considering a random guess will fetch you an accuracy of 33%."
      ],
      "id": "65558d2f"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment4.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bd17df20df94f8691739e32587bfcd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8872d2e18ab94ab89198f7a5c7953c28",
              "IPY_MODEL_b3aabdbfbe54402d82db10e4b429eed4",
              "IPY_MODEL_c88e106beec443f48f96679a7ec0e4a6"
            ],
            "layout": "IPY_MODEL_5d302af0d9cb41529723fa49a980ce88"
          }
        },
        "8872d2e18ab94ab89198f7a5c7953c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5119e0d9fa39447bbd6272612f609681",
            "placeholder": "​",
            "style": "IPY_MODEL_cd7a6c769fb445bf9f66e565782c6fca",
            "value": "Downloading: 100%"
          }
        },
        "b3aabdbfbe54402d82db10e4b429eed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56ca8910cd3e4248b2d40fcac7244b8d",
            "max": 871891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25e53c69f9c44607b365a3846121b52b",
            "value": 871891
          }
        },
        "c88e106beec443f48f96679a7ec0e4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5b31063f15247da84e697a8b6e4ad71",
            "placeholder": "​",
            "style": "IPY_MODEL_c9b5633961ee41528896178aade62344",
            "value": " 851k/851k [00:00&lt;00:00, 1.37MB/s]"
          }
        },
        "5d302af0d9cb41529723fa49a980ce88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5119e0d9fa39447bbd6272612f609681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd7a6c769fb445bf9f66e565782c6fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56ca8910cd3e4248b2d40fcac7244b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e53c69f9c44607b365a3846121b52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5b31063f15247da84e697a8b6e4ad71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b5633961ee41528896178aade62344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c77122f70b94237b64c1e3b37b25eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dd7aef0706545cf9889bf27147decc5",
              "IPY_MODEL_d5c36871914b4e6590d5d26164e34157",
              "IPY_MODEL_95ea78b56cb64e9bae4a92b009fdf9cd"
            ],
            "layout": "IPY_MODEL_6af601c49b9c4678a488c58cd3e9e2b2"
          }
        },
        "1dd7aef0706545cf9889bf27147decc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2f4f938bc194baa9e2411895826a600",
            "placeholder": "​",
            "style": "IPY_MODEL_81cfb45939ed4dc8845074083b271696",
            "value": "Downloading: 100%"
          }
        },
        "d5c36871914b4e6590d5d26164e34157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8684cdaa79f441f58e3830ad98dae2ab",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f2a60f184cc43b186b0a9ab4286868e",
            "value": 28
          }
        },
        "95ea78b56cb64e9bae4a92b009fdf9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc9e703f94b4510815b879bf6c00716",
            "placeholder": "​",
            "style": "IPY_MODEL_d6d280a835c741f1803fdafe522c22ed",
            "value": " 28.0/28.0 [00:00&lt;00:00, 545B/s]"
          }
        },
        "6af601c49b9c4678a488c58cd3e9e2b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f4f938bc194baa9e2411895826a600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81cfb45939ed4dc8845074083b271696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8684cdaa79f441f58e3830ad98dae2ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f2a60f184cc43b186b0a9ab4286868e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcc9e703f94b4510815b879bf6c00716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d280a835c741f1803fdafe522c22ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "592d676920fc4148a638cbf0af7d4e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f5cf935dc5245b2bb3e8d56645b73e1",
              "IPY_MODEL_d1b8733c048f42c19de978f4c0497294",
              "IPY_MODEL_def3a82c17e64f5ca374a140140036a4"
            ],
            "layout": "IPY_MODEL_f4df4dd431e742dc8a985f67c9df273a"
          }
        },
        "2f5cf935dc5245b2bb3e8d56645b73e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_159259beb3fd48f099eba5296cfe1253",
            "placeholder": "​",
            "style": "IPY_MODEL_e121d4913a4544299a732ca19dccb263",
            "value": "Downloading: 100%"
          }
        },
        "d1b8733c048f42c19de978f4c0497294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94b0eee34095414ca94b5029c1302263",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e721a5376264382a48420e9007d3998",
            "value": 625
          }
        },
        "def3a82c17e64f5ca374a140140036a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed79384fa61d4093bc76803b4dc6cfa1",
            "placeholder": "​",
            "style": "IPY_MODEL_9ecb0c5cb5e1429f86de669e966b28d3",
            "value": " 625/625 [00:00&lt;00:00, 9.29kB/s]"
          }
        },
        "f4df4dd431e742dc8a985f67c9df273a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "159259beb3fd48f099eba5296cfe1253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e121d4913a4544299a732ca19dccb263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94b0eee34095414ca94b5029c1302263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e721a5376264382a48420e9007d3998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed79384fa61d4093bc76803b4dc6cfa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ecb0c5cb5e1429f86de669e966b28d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0255e49523a42be872a13b15b50bb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaa6e207d5df4fbb8ffb55c59b3a5027",
              "IPY_MODEL_98255546fe1e4a70a1e2200bd39e9b5d",
              "IPY_MODEL_15344f9efcae4a319b4fb6c0a1f92060"
            ],
            "layout": "IPY_MODEL_eeaf347b027c41eab23bbcbdc74b93c9"
          }
        },
        "eaa6e207d5df4fbb8ffb55c59b3a5027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c78338d90d4493092c73e24c34d0157",
            "placeholder": "​",
            "style": "IPY_MODEL_cecb9de27f9e48a68100bc5c10e1a1b8",
            "value": "Downloading: 100%"
          }
        },
        "98255546fe1e4a70a1e2200bd39e9b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e70d4fbf82da4411ba7e088f3704c222",
            "max": 672271273,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3486d34bd3f443e9a2814248d3855d6",
            "value": 672271273
          }
        },
        "15344f9efcae4a319b4fb6c0a1f92060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77aed5a8df3141c8bc89980b5da52544",
            "placeholder": "​",
            "style": "IPY_MODEL_188e1ca6e08143cbb06c282da423cde2",
            "value": " 641M/641M [00:16&lt;00:00, 46.3MB/s]"
          }
        },
        "eeaf347b027c41eab23bbcbdc74b93c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c78338d90d4493092c73e24c34d0157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cecb9de27f9e48a68100bc5c10e1a1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e70d4fbf82da4411ba7e088f3704c222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3486d34bd3f443e9a2814248d3855d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77aed5a8df3141c8bc89980b5da52544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188e1ca6e08143cbb06c282da423cde2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}